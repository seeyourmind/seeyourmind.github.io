<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>pip自查手册</title>
      <link href="/2023/08/21/Python-pip/"/>
      <url>/2023/08/21/Python-pip/</url>
      
        <content type="html"><![CDATA[<p>pip 是 Python 包管理工具，该工具提供了对Python 包的查找、下载、安装、卸载的功能。</p><span id="more"></span><h1 id="日常用法"><a href="#日常用法" class="headerlink" title="日常用法"></a>日常用法</h1><pre><code class="bash"># 查看pip版本pip --version# 查看已安装包pip list# 安装包：通过使用==, &gt;=, &lt;=, &gt;, &lt; 来指定一个版本号。pip install some-packagepip install some-package==1.0pip install some-package&gt;=1.0# 更新包：通过使用==, &gt;=, &lt;=, &gt;, &lt; 来指定一个版本号。pip install --upgrade some-package# 卸载包pip uninstall some-package# 其它pip search some-package     # 搜索包pip show                    # 显示安装包信息pip show -f some-package    # 查看指定包的详细信息pip list -o                 # 查看可升级的包# pip升级# Linux 或 macOSpip install --upgrade pip    # python2.xpip3 install --upgrade pip   # python3.x# Windows 平台升级：python -m pip install -U pip   # python2.xpython -m pip3 install -U pip    # python3.x</code></pre><h1 id="查看与配置源"><a href="#查看与配置源" class="headerlink" title="查看与配置源"></a>查看与配置源</h1><p>临时使用<code>-i</code></p><pre><code class="bash">pip install -i https://pypi.tuna.tsinghua.edu.cn/simple some-package</code></pre><p>永久更改</p><pre><code class="bash"># 升级 pip 到最新的版本 (&gt;=10.0.0) 后进行配置pip install pip -Upip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple# 清华源：https://pypi.tuna.tsinghua.edu.cn/simple# 阿里源：http://mirrors.aliyun.com/pypi/simple/# 中科大：https://pypi.mirrors.ustc.edu.cn/simple# PS：如果您到 pip 默认源的网络连接较差，临时使用镜像站来升级 pippip install -i https://pypi.tuna.tsinghua.edu.cn/simple pip -U</code></pre><p>查看当前pip源</p><pre><code class="bash">pip config list</code></pre><h1 id="修复Error：module-‘lib’-has-no-attribute-‘X509-V-FLAG-CB-ISSUER-CHECK’"><a href="#修复Error：module-‘lib’-has-no-attribute-‘X509-V-FLAG-CB-ISSUER-CHECK’" class="headerlink" title="修复Error：module ‘lib’ has no attribute ‘X509_V_FLAG_CB_ISSUER_CHECK’"></a>修复Error：module ‘lib’ has no attribute ‘X509_V_FLAG_CB_ISSUER_CHECK’</h1><pre><code class="bash">sudo rm -rf /usr/lib/python3/dist-packages/OpenSSLsudo pip3 install pyopensslsudo pip3 install pyopenssl --upgrade</code></pre><h1 id="好玩的包"><a href="#好玩的包" class="headerlink" title="好玩的包"></a>好玩的包</h1><pre><code class="bash">pip install nvitop    # NVIDIA显卡可视化pip install wandb     # DL实验数据可视化</code></pre>]]></content>
      
      
      <categories>
          
          <category> Python </category>
          
          <category> AI </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Tools </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Brother打印机维护日志</title>
      <link href="/2023/04/24/Brother-maintain/"/>
      <url>/2023/04/24/Brother-maintain/</url>
      
        <content type="html"><![CDATA[<h1 id="解决电脑无法自动识别打印机扫描驱动的问题"><a href="#解决电脑无法自动识别打印机扫描驱动的问题" class="headerlink" title="解决电脑无法自动识别打印机扫描驱动的问题"></a>解决电脑无法自动识别打印机扫描驱动的问题</h1><p>解决办法是使用官方提供的软件</p><blockquote><ol><li>进入官方下载地址 <a href="http://www.95105369.com/">🔗链接</a></li><li>输入产品型号<code>DCP-L2550DW</code>查询所需驱动与软件安装包</li><li>下载<code>全套驱动程序和软件包</code></li></ol></blockquote><span id="more"></span><h1 id="打印机加粉或更换粉盒"><a href="#打印机加粉或更换粉盒" class="headerlink" title="打印机加粉或更换粉盒"></a>打印机加粉或更换粉盒</h1><blockquote><ol><li>取下粉盒加粉或换新</li><li>粉盒复位 （仅在加粉的情况下执行）</li><li>按打印机顶部的：功能键，里面有个常规设置，然后更换墨盒设置，然后点继续，再接受 </li><li>如果经过以上步骤打印机依然提示墨粉用尽请按照下图执行重置操作</li><li>正常的情况应该是：打印机不提醒缺墨，墨粉容量更新为全满</li></ol></blockquote><p><img src="/../images/O1CN01ymbyie2N6CyWBYcuy_!!2201444729913-0-ampmedia.jpg" alt="加粉清零操作"></p><h2 id="原装粉盒"><a href="#原装粉盒" class="headerlink" title="原装粉盒"></a>原装粉盒</h2><p><a href="https://v.youku.com/v_show/id_XNDExMDY2MTY2NA==.html?spm=a2h0c.8166622.PhoneSokuUgc_5.dtitle">原装TN2412粉盒演示视频</a><br><a href="https://v.youku.com/v_show/id_XNDc3MjI2NTY0MA==.html?spm=a2hzp.8244740.0.0">原装TN2412粉盒复位</a></p><h2 id="国产嘉彩乐粉盒"><a href="#国产嘉彩乐粉盒" class="headerlink" title="国产嘉彩乐粉盒"></a>国产嘉彩乐粉盒</h2><p>加粉<br><img src="/../images/O1CN01UHerpU2N6Cyfk4yeQ_!!2201444729913-0-ampmedia.jpg"><br>复位<br><img src="/../images/Snipaste_2022-09-07_09-40-43.png"><br><strong>注意事项</strong>：由于国产粉盒复位大齿轮里的弹簧没有像原装的那样固定，所在复位时一定要注意弹簧的位置，如果弹簧如下图白色⚙那样翘起请将其设置成灰色⚙那样<br><img src="/../images/O1CN01GaPtJF27uYfQuLSms_!!0-amp.jpg"></p>]]></content>
      
      
      <categories>
          
          <category> Logs </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>深度学习模型可视化工具-WandB</title>
      <link href="/2023/03/24/Python-WandB/"/>
      <url>/2023/03/24/Python-WandB/</url>
      
        <content type="html"><![CDATA[<p>W&amp;B是一款开源的，用于记录实验数据的工具。wandb相比于tensorboard之类的工具，有更加丰富的用户管理，团队管理功能，更加方便团队协作。</p><span id="more"></span><h1 id="1-安装"><a href="#1-安装" class="headerlink" title="1.安装"></a>1.安装</h1><p>wandb是一个Python库，所以使用pip来安装。</p><pre><code class="bash">pip install wandb -i https://pypi.tuna.tsinghua.edu.cn/simple</code></pre><p>然后在<a href="https://wandb.ai/">wandb官网</a>注册一个账号，获取该账号的私钥<a href="https://wandb.ai/authorize">API-key</a>，然后在命令行执行：</p><pre><code class="bash">wandb login# 输入秘钥</code></pre><blockquote><p>login这一步也可以在代码中设置</p></blockquote><h1 id="2-在代码中的用法"><a href="#2-在代码中的用法" class="headerlink" title="2.在代码中的用法"></a>2.在代码中的用法</h1><p><a href="https://docs.wandb.ai/ref/python/">Python API说明文档</a>  <a href="https://docs.wandb.ai/guides/track/environment-variables">环境变量说明文档</a>  <a href="https://blog.csdn.net/xieocean/article/details/128120305?spm=1001.2014.3001.5501">简单入门教程1</a>  <a href="https://zhuanlan.zhihu.com/p/493093033">简单入门教程2</a></p><pre><code class="python">import wandb# 配置环境参数，不在命令行中login# 配置私钥os.environ[&#39;WANDB_API_KEY&#39;] = &#39;local-XXXXX&#39;# 配置服务器地址--以本地部署为例# 如果是wandb服务器则改为https://wandb.aios.environ[&#39;WANDB_BASE_URL&#39;] = &#39;http://local_host:port&#39;# 配置运行模式 [online|offline|disabled]os.environ[&#39;WANDB_MODE&#39;] = &#39;disabled&#39;# 【可选】记录一些模型的配置参数base_config = &#123;    &#39;architecture&#39;: &#39;模型结构描述&#39;,    &#39;learning_rate&#39;: &#39;你想记录的参数&#39;,    &#39;infra&#39;: &#39;AWS云服务器&#39;    &#125;run = wandb.init(    name=&#39;可选：定义run的名字，方便查看&#39;,    project=&#39;必选：在wandb中创建的项目名&#39;,     entity=&#39;可选：&#39;,    notes=&#39;可选：一些返回给用户的记录性描述&#39;,    tags=[&#39;baseline&#39;, &#39;可选：方便过滤查看&#39;],    config=base_config,    )# wandb通过log()函数，记录训练数据run.log(&#123;&#39;loss&#39;: loss&#125;)# finish函数结束wandb并将记录文件上传到服务器run.finish()</code></pre><h1 id="3-本地部署"><a href="#3-本地部署" class="headerlink" title="3.本地部署"></a>3.本地部署</h1><p><strong>1.拉取docker镜像</strong></p><pre><code class="bash">docker pull wandb/local</code></pre><p><strong>2.去<a href="https://deploy.wandb.ai/deploy">官网</a>申请License</strong></p><blockquote><p>本地部署需要获取License，免费试用30天<br>Origination填用户名<br>PS: 如果License过期可以联系客服再次申请（对于学生免费）</p></blockquote><p><strong>3.启动docker镜像</strong></p><pre><code class="bash"># 确保8080端口没有被占用，占用了就换别的端口sudo docker run --rm -d -e LOCAL_RESTORE=true -e HOST=http://&lt;your host&gt;:&lt;your port&gt; -e LICENSE=&lt;your license&gt; -p &lt;your port&gt;:8080 --name wandb-local wandb/local</code></pre><p><strong>4.创建用户</strong><br>网页创建</p><blockquote><p>打开网站 http:&#x2F;&#x2F;<your_host>:<your_port>，创建账户<br>如果无法创建，可以根据<a href="https://github.com/wandb/server/issues/44#issuecomment-962156373">这里</a>进行修复</p></blockquote><p>手动创建，更多细节详见<a href="https://github.com/wandb/local/issues/66">这里</a></p><pre><code class="bash"># login the containerdocker exec -it wandb-local bash vi /vol/env/users.htpasswd  # delete the line contain local@wandb.com /usr/local/bin/local password &lt;your add username&gt;# input your passwordexit</code></pre><p><strong>5.登录</strong><br>浏览器：</p><blockquote><p>http:&#x2F;&#x2F;<your host>:8080&#x2F;home</p></blockquote><p>Shell：</p><pre><code class="bash">wandb login --host=http://&lt;your host&gt;:8080 &lt;your api key&gt;# wandb local -p 8080 -e LOCAL_RESTORE=true</code></pre>]]></content>
      
      
      <categories>
          
          <category> AI </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Tools </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>记一次基于Neo4j的网站开发经历</title>
      <link href="/2023/03/12/SoftwareDevelopment-Web/"/>
      <url>/2023/03/12/SoftwareDevelopment-Web/</url>
      
        <content type="html"><![CDATA[<h1 id="项目使用的技术栈"><a href="#项目使用的技术栈" class="headerlink" title="项目使用的技术栈"></a>项目使用的技术栈</h1><table><thead><tr><th align="center">名称</th><th align="center">作用端</th><th align="center">开发文档</th></tr></thead><tbody><tr><td align="center">Neo4j</td><td align="center">知识图谱处理数据库</td><td align="center"><a href="https://zhuanlan.zhihu.com/p/88745411">参考介绍</a></td></tr><tr><td align="center">Vue-Element-Admin</td><td align="center">前端静态页面</td><td align="center"><a href="https://panjiachen.github.io/vue-element-admin-site/zh/">中文文档</a></td></tr><tr><td align="center">Flask</td><td align="center">Python后端接口设计</td><td align="center"><a href="https://flask.net.cn/quickstart.html">中文文档</a></td></tr><tr><td align="center">Gunicorn</td><td align="center">WSGI HTTP服务器</td><td align="center"><a href="https://zhuanlan.zhihu.com/p/102716258">参考介绍</a></td></tr><tr><td align="center">Nginx</td><td align="center">代理服务器</td><td align="center"><a href="https://zhuanlan.zhihu.com/p/34943332">参考介绍</a></td></tr></tbody></table><span id="more"></span><h1 id="Neo4j"><a href="#Neo4j" class="headerlink" title="Neo4j"></a>Neo4j</h1><p>Neo4j依赖JAVA环境，所以在正式安装Neo4j之前应先确保本机正确配置的Java环境。</p><h2 id="配置Java环境"><a href="#配置Java环境" class="headerlink" title="配置Java环境"></a>配置Java环境</h2><pre><code class="bash"># 1. 下载JDK：http://www.codebaoku.com/jdk/jdk-index.htmlExample: jdk-15.0.2_linux-x64_bin.tar.gz# 2. 解压tar -xzvf jdk-8u131-linux-x64.tar.gz# 3. 查看Java安装位置 &gt;表示输出结果which java&gt; /usr/local/jdk/jdk-15.0.2/bin/java# 4.1 配置环境变量vim /etc/profile# 4.2 在文件末尾添加export JAVA_HOME=/usr/local/jdk/jdk-15.0.2export CLASSPATH=.:JAVA_HOME/lib:$&#123;CLASSPATH&#125;export PATH=$JAVA_HOME/bin:$PATH# 4.3 退出保存sudo source /etc/profile# 4.4 验证java -version&gt; java version &quot;15.0.2&quot; 2021-01-19&gt; Java(TM) SE Runtime Environment (build 15.0.2+7-27)&gt; Java HotSpot(TM) 64-Bit Server VM (build 15.0.2+7-27, mixed mode, sharing)</code></pre><h2 id="安装Neo4j"><a href="#安装Neo4j" class="headerlink" title="安装Neo4j"></a>安装Neo4j</h2><pre><code class="bash"># 1. 下载Linux安装包wget https://neo4j.com/business-subscription/?edition=enterprise&amp;release=4.4.18&amp;flavour=unix# 2. 解压tar -xzvf neo4j-community-4.4.18-unix.tar.gz# 3. 启动cd [Neo4j安装目录]/bin./neo4j console# 4. 浏览器中访问 http://localhost:7474# 账号密码默认都是neo4j</code></pre><h2 id="项目中额外的配置"><a href="#项目中额外的配置" class="headerlink" title="项目中额外的配置"></a>项目中额外的配置</h2><p>项目采用<a href="https://py2neo.org/2021.1/"><code>py2neo</code></a>访问和操作Neo4j，基于Apoc插件对数据进行导入与导出操作</p><h3 id="安装Apoc插件"><a href="#安装Apoc插件" class="headerlink" title="安装Apoc插件"></a>安装Apoc插件</h3><p>去<a href="https://github.com/neo4j-contrib/neo4j-apoc-procedures/releases">GitHub</a>上下载对应版本的jar包，并将jar放置在Neo4j安装目录里的plugins文件夹下。</p><blockquote><p>本项目使用的是apoc-4.4.0.14-all.jar<br>可以在Neo4j的web端使用return apoc.version()查看是否安装成功</p></blockquote><h3 id="修改Neo4j的配置文件"><a href="#修改Neo4j的配置文件" class="headerlink" title="修改Neo4j的配置文件"></a>修改Neo4j的配置文件</h3><pre><code class="ini"># 文件路径：[Neo4j安装根目录]/bin/conf/config.inidbms.default_listen_address=0.0.0.0dbms.security.procedures.unrestricted=algo.*dbms.security.procedures.unrestricted=apoc.*apoc.export.file.enabled=trueapoc.import.file.enabled=true</code></pre><h1 id="Vue-Element-Admin"><a href="#Vue-Element-Admin" class="headerlink" title="Vue-Element-Admin"></a>Vue-Element-Admin</h1><p>一个基于vue和<a href="https://element.eleme.cn/#/zh-CN">element-ui</a>实现的后台前端框架。</p><h2 id="安装与使用"><a href="#安装与使用" class="headerlink" title="安装与使用"></a>安装与使用</h2><h3 id="环境要求"><a href="#环境要求" class="headerlink" title="环境要求"></a>环境要求</h3><p>安装Node.js，为避免构建项目是发生奇奇怪怪的错误，建议手动安装最新版本</p><pre><code class="bash"># 官网下载：https://nodejs.org/zh-cn/download/Exmaple: node-v18.14.2-linux-x64.tar.xz# 解压tar -xvf node-v16.13.0-linux-x64.tar.xz# 建立软连接，变为全局ln -s [安装目录]/bin/npm /usr/local/binln -s [安装目录]/bin/node /usr/local/bin# 检验是否为全局node -v&gt; v18.14.2</code></pre><h3 id="下载模板"><a href="#下载模板" class="headerlink" title="下载模板"></a>下载模板</h3><p>去<a href="https://github.com/PanJiaChen/vue-element-admin">Github</a>下载模板</p><h3 id="构建项目"><a href="#构建项目" class="headerlink" title="构建项目"></a>构建项目</h3><pre><code class="bash"># 开发阶段npm run dev# 发布阶段npm run build:prod# 清理缓存npm cache verify</code></pre><blockquote><p>如果这里无法完成构建，一般需要卸载并重装最新版nodejs，删除项目中的node_modules、package-lock.json</p></blockquote><h3 id="主要项目目录"><a href="#主要项目目录" class="headerlink" title="主要项目目录"></a>主要项目目录</h3><ul><li><code>mock</code>：可用来生成服务端的模拟数据</li><li><code>src/views</code>：视图文件夹</li><li><code>src/router/index.js</code>：配置页面路由</li></ul><h1 id="Flask和Gunicorn"><a href="#Flask和Gunicorn" class="headerlink" title="Flask和Gunicorn"></a>Flask和Gunicorn</h1><p>直接pip安装即可</p><h2 id="启动一个最简单的Flask服务"><a href="#启动一个最简单的Flask服务" class="headerlink" title="启动一个最简单的Flask服务"></a>启动一个最简单的Flask服务</h2><pre><code class="python"># 入口文件app.pyfrom flask import Flaskapp = Flask(__name__)@app.route(&#39;/&#39;)def hello_world():    return &#39;Hello, World!&#39;if __name__ ==&#39;__main__&#39;:    app.run(host=&#39;0.0.0.0&#39;, port=5000, debug=True)# 运行文件之后可以在http://127.0.0.1:5000访问</code></pre><h2 id="本项目布局"><a href="#本项目布局" class="headerlink" title="本项目布局"></a>本项目布局</h2><pre><code>/flask-app├── App│   ├── __init__.py│   ├── settings.py                 # Flask配置文件│   ├── api/│   │   └── api_test.py             # 自定义API文件：定义blueprint和route│   └── models│       ├── __init__.py│       └── sub_model/│               ├── __init__.py│               └── model1.py       # 自定义接口所需函数├── statics                         # 存放静态数据资源│   ├── data1/│   ├── data2/│   └── data3/└── app.py                          # 项目入口文件</code></pre><h2 id="Gunicorn"><a href="#Gunicorn" class="headerlink" title="Gunicorn"></a>Gunicorn</h2><p><strong>为什么需要Gunicorn或uWSGI？</strong></p><blockquote><p>由于Flask自带的wsgi性能低，仅适用于调试开发阶段，在真实线上必须用Gunicorn+Nginx获得更好的性能和安全性，其本质是为了提升服务器并发处理能力。</p></blockquote><p><strong>为什么有了Gunicorn还需要再套一层Nginx？</strong></p><blockquote><p>Nginx更安全Nginx能更好地处理静态资源（通过一些http request header），Nginx也可以缓存一些动态内容；Nginx可以更好地配合CDN，可以进行多台机器的负载均衡；不需要在wsgi server那边处理keep alive，让Nginx来处理slow client；还有一个更隐蔽的区别是，像uWSGI支持的是wsgi协议，Nginx支持的是http协议，它们之间是有区别的。<br>一台服务器同时运行多服务或者前后端分离时，可以用Nginx来分发。</p></blockquote><p><strong>使用Gunicorn启动Flask应用</strong></p><pre><code class="bash"># 1.启动gunicorn -w 4 -t 300 -b 0.0.0.0:5000 app:app# 2.查看状态# 使用树形结构查看PIDpstree -ap|grep gunicorn# 根据端口查看PIDlsof -i:5000# 3.重启kill -HUP [master_PID]# 4.关闭kill -9 [master_PID]</code></pre><h1 id="Nginx"><a href="#Nginx" class="headerlink" title="Nginx"></a>Nginx</h1><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><pre><code class="bash"># 安装sudo apt update  # 更新安装源sudo apt install nginx# 验证sudo systemctl status nginx# 启动 停止 重启sudo systemctl start/stop/restart nginx# 测试启动http://localhost</code></pre><h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a><a href="https://blog.csdn.net/qq_41070393/article/details/113977572">配置</a></h2><h3 id="配置文件说明"><a href="#配置文件说明" class="headerlink" title="配置文件说明"></a>配置文件说明</h3><ul><li><code>/etc/nginx/nginx.conf</code>：主配置文件</li><li><code>/etc/nginx/conf.d/*.conf</code>：独立配置Server，通过引用的方式调用</li><li><code>/etc/nginx/sites-enabled/*.*</code>：Nginx会加载该目录下任何名称的配置文件</li><li><code>/etc/nginx/sites-available/*.*</code>：用于存放网站的配置文件，意为可用的网站列表，用于在需要时链接到<code>sites-enabled</code>中作为需要启用的网站。</li></ul><h3 id="本项目的配置"><a href="#本项目的配置" class="headerlink" title="本项目的配置"></a>本项目的配置</h3><p><strong>部署前端</strong></p><pre><code class="bash"># 发布Vuenpm run build:prod# 将生成dist目录：其中静态文件为[static、favicon.ico、index.html]# 可以选择移动或是复制到一个单独的路径，也可以直接使用dist路径# 在本项目中我是选择了前者mv dist [项目路径]/web</code></pre><p><strong>部署后端</strong><br>使用Gunicorn启动Flask</p><p><strong>修改Nginx服务配置</strong></p><pre><code class="ini"># /etc/nginx/conf.d/myApp.com.confserver &#123;    listen 80;  # 监听端口    server_name XXXXXXXX.imdo.co;  # 花生壳内网穿透域名    charset utf-8;    client_max_body_size 75M;    # 前端-Vue-Element-Admin    location / &#123;    proxy_set_header Host $host;    proxy_set_header X-Real-IP $remote_addr;    proxy_set_header REMOTE-HOST $remote_addr;    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;    root  [项目路径]/web;  # 站点的根目录    try_files $uri $uri/ /index.html;    index  /index.html;    &#125;    # 后端-Flask+Gunicorn    location /api/ &#123;    proxy_set_header Host $host;    proxy_set_header X-Real-IP $remote_addr;    proxy_set_header REMOTE-HOST $remote_addr;    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;    add_header Access-Control-Allow-Methods *;        add_header Access-Control-Allow-Origin $http_origin;        proxy_pass http://127.0.0.1:5000/;        # 设置超时，默认30s，避免后台响应时间长触发504错误        proxy_connect_timeout 300s;        proxy_send_timeout 300s;        proxy_read_timeout 300s;    &#125;&#125;</code></pre><p><strong>Gzip配置</strong><br>由于<code>vue</code>打包之后的<code>chunk-libs.js</code>文件过大导致前端页面加载过慢，一种简单的处理方式是<strong>Nginx服务器配置静态压缩</strong></p><pre><code class="ini">server&#123;    # 将下面的内容直接合并到/etc/nginx/conf.d/myApp.com.conf的server&#123;&#125;中    gzip on;    gzip_static on;    gzip_min_length 1k;    gzip_comp_level 9;    gzip_types text/plain application/javascript application/x-javascript text/css application/xml text/javascript application/x-httpd-php image/jpeg image/gif image/png;    gzip_vary on;    gzip_disable &quot;MSIE [1-6]\.&quot;;&#125;</code></pre>]]></content>
      
      
      <categories>
          
          <category> 软件开发记录 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Web开发 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>第2章 线性代数与矩阵论</title>
      <link href="/2022/10/03/Learning-MathematicsOfMachineLearning-chap2/"/>
      <url>/2022/10/03/Learning-MathematicsOfMachineLearning-chap2/</url>
      
        <content type="html"><![CDATA[<blockquote><p>线性代数是多元函数微积分的基础，在机器学习和深度学习中扮演着重要角色，在图论、随机过程中被广泛应用。</p></blockquote><span id="more"></span><h2 id="2-1-向量及其运算"><a href="#2-1-向量及其运算" class="headerlink" title="2.1 向量及其运算"></a>2.1 向量及其运算</h2><h3 id="2-1-1-基本概念"><a href="#2-1-1-基本概念" class="headerlink" title="2.1.1 基本概念"></a>2.1.1 基本概念</h3><p>向量（Vector）是具有大小和方向的量，是由多个数构成的一维数组，每个数称为向量的分量，分量的个数称为向量的维数。标量有大小无方向。</p><h3 id="2-1-2-基本运算"><a href="#2-1-2-基本运算" class="headerlink" title="2.1.2 基本运算"></a>2.1.2 基本运算</h3><ul><li>转置（Transpose）：行列位置互换，$x^T$</li><li>加法：对应分量相加，满足交换律和结合律，平行四边形法则</li><li>数乘：标量与每个分量相乘，满足分配律</li><li>內积（Inner product）：对应分量乘积之和，$x\cdot y&#x3D;x^Ty&#x3D;\sum_{i&#x3D;1}^n{x_iy_i}$<br>$$<br>\begin{align}<br>x^Ty&#x3D;y^Tx&amp;,\qquad(Cx)^Ty&#x3D;Cx^Ty\<br>(x+y)^Tz&#x3D;x^Tz+y^Tz&amp;,\qquad z^T(x+y)&#x3D;z^Tx+z^Ty<br>\end{align}<br>$$</li><li>正交（Orthogonal）：內积为0，正交是几何中垂直概念在高维空间的推广</li><li>Hadamard积：对应分量相乘，结果为相同维数的向量，$x\odot y$。它可以简化问题的表述，在反向传播和各种梯度下降法中被使用。</li></ul><h3 id="2-1-3-向量的范数"><a href="#2-1-3-向量的范数" class="headerlink" title="2.1.3 向量的范数"></a>2.1.3 向量的范数</h3><p>向量的范数（Norm）是向量模长的推广，向量的L-p范数是一个标量，定义为<br>$$<br>|x|<em>p&#x3D;\left(\sum</em>{i&#x3D;1}^n|x_i|^p\right)^{1&#x2F;p}<br>$$<br>常用的L1范数是绝对值之和，L2范数（Euclidean Norm）是向量的模长，两者被用于构造正则化项。</p><ul><li>对于非<strong>0</strong>向量，通过数乘向量模的倒数可以将向量单位化（标准化）使其长度为1</li><li>当$p&#x3D;\infin$时，称为$L-\infin$范数，$|x|_\infin&#x3D;\max{x_i}$，是L-p范数的极限</li><li>柯西-施瓦茨Cauchy-Schwarz不等式：$x^Ty\leq|x|\cdot|y|$，<code>L2范数</code></li><li>向量夹角计算公式：$\displaystyle{\cos\theta&#x3D;\frac{x^Ty}{|x|\cdot|y|}}$</li><li>对于长度确定的两个向量，夹角为0时它们的內积最大，夹角为$\pi$时它们的內积最小。这一结论在梯度下降和最速下降法中使用。</li><li>L2范数满足三角不等式：$|x+y|\leq|x|+|y|$</li><li>距离函数：满足非负性，对称性，三角不等式</li></ul><h3 id="2-1-4-解析几何"><a href="#2-1-4-解析几何" class="headerlink" title="2.1.4 解析几何"></a>2.1.4 解析几何</h3><ul><li>超平面（hyperplane）方程：$w^Tx+b&#x3D;0$，$w$法向量</li><li>点到超平面的距离：$\displaystyle{d&#x3D;\frac{|w^Tx+b|}{|w|_2}}$</li></ul><h3 id="2-1-5-线性相关性"><a href="#2-1-5-线性相关性" class="headerlink" title="2.1.5 线性相关性"></a>2.1.5 线性相关性</h3><ul><li>线性组合（Linear Combination）：$x&#x3D;C_1x_1+\cdots+C_nx_n$</li><li>如果存在不全为0的系数是的线性组合为零向量，则这组向量线性相关，否则线性无关（线性独立，Linear Independence）。<code>线性相关意味着这组向量有冗余、最大线性无关的向量子集称为极大线性无关组</code></li></ul><h3 id="2-1-6-向量空间"><a href="#2-1-6-向量空间" class="headerlink" title="2.1.6 向量空间"></a>2.1.6 向量空间</h3><ul><li>向量空间（Vector space，线性空间）对集合内的向量加法和数乘运算封闭</li><li>向量空间的极大线性无关组称为空间的基，基所包含的向量个数称为空间的维数</li><li>基前面的系数称为这组基下的坐标，如果基向量相互正交称为正交基，长度为1的正交基称为标准正交基 <code>格拉姆-施密特Gram-Schmidt正交化：通过向量投影构造垂直向量</code></li></ul><h3 id="2-1-8-应用–支持向量机"><a href="#2-1-8-应用–支持向量机" class="headerlink" title="2.1.8 应用–支持向量机"></a>2.1.8 应用–支持向量机</h3><p>支持向量机（不考虑核函数）是线性分类器的特例，是最大化分类间隔的线性分类器。其目标是寻找一个分类超平面，它不仅能正确地分类每一个样本，并且要使得每一类样本中距离超平面最近的样本到超平面的距离尽可能远，这样有更好的泛化性能。</p><ul><li>基于类别标签的约束：$\displaystyle{y_i(w^Tx_i+b)&gt;0}$</li><li>超平面方程去冗余：$\displaystyle{\min_{x_i}{|w^Tx_i+b|&#x3D;1}}$</li><li>多分类样本到超平面的距离：$\displaystyle{d(w,b)&#x3D;\frac{N}{|w|}}$</li><li>两分类支持向量机求解优化问题可以写成：$\min{\frac{1}{2}w^Tw},\qquad y_i(w^Tx_i+b)\geq1$</li></ul><h2 id="2-2-矩阵及其运算"><a href="#2-2-矩阵及其运算" class="headerlink" title="2.2 矩阵及其运算"></a>2.2 矩阵及其运算</h2><p>实矩阵、复矩阵、方阵、主对角线、对角矩阵（diag，$\Lambda$）、单位矩阵（$I$）、零矩阵、分块矩阵、格拉姆矩阵（Gram，其中的每个元素$G_{ij}$等于向量$x_i$和$x_j$的內积，是一个对称矩阵）</p><h3 id="2-2-2-基本运算"><a href="#2-2-2-基本运算" class="headerlink" title="2.2.2 基本运算"></a>2.2.2 基本运算</h3><ul><li>$(A+B)^T&#x3D;A^T+B^T$</li><li>使用矩阵可以简化线性方程组的表述：$系数矩阵\times x&#x3D;常数矩阵$，增广矩阵</li><li>矩阵乘法与转置满足<em>穿脱原则</em>：$(AB)^T&#x3D;B^TA^T$</li></ul><h3 id="2-2-3-逆矩阵"><a href="#2-2-3-逆矩阵" class="headerlink" title="2.2.3 逆矩阵"></a>2.2.3 逆矩阵</h3><p>逆矩阵对应于标量的倒数运算，对于$n$阶矩阵$A$，如果存在另一个$n$阶矩阵$B$，使得它们的乘积为单位矩阵，即$AB&#x3D;I$</p><ul><li>可逆矩阵也称为非奇异矩阵，不可逆矩阵也称为奇异矩阵。</li><li>如果矩阵可逆，则其逆矩阵唯一。</li><li>矩阵可逆的充分必要条件是满秩。</li><li>$(AB)^{-1}&#x3D;B^{-1}A^{-1}\qquad(A^{-1})^{-1}&#x3D;A\qquad(A^T)^{-1}&#x3D;(A^{-1})^T\qquad(\lambda A)^{-1}&#x3D;\lambda^{-1}A^{-1}$</li><li>可通过初等行变换求矩阵的逆，即将$(A\ I)$转变成$(I\ A^{-1})$</li><li>如果一个方阵满足$AA^T&#x3D;A^TA&#x3D;I$则称为正交矩阵（orthogonal matrix）</li></ul><p><strong>矩阵的秩</strong><br>对于$m\times n$矩阵$A$，秩为矩阵线性无关的行向量或列向量的最大数量。<br>$$<br>r(A)\leq\min(m,n)\qquad r(A)&#x3D;r(A^T)\qquad r(A+B)\leq r(A)+r(B)\qquad r(AB)\leq\min(r(A),r(B))<br>$$</p><p><strong>正交矩阵</strong><br>正交矩阵的行向量均为单位向量且相互正交，构成标准正交基。正交矩阵的乘积、逆矩阵、转置，仍然是为正交矩阵。</p><h3 id="2-2-4-矩阵的范数"><a href="#2-2-4-矩阵的范数" class="headerlink" title="2.2.4 矩阵的范数"></a>2.2.4 矩阵的范数</h3><p>矩阵$W$的范数定义为：$\displaystyle{|W|<em>p&#x3D;\max</em>{x\neq0}\frac{|Wx|<em>p}{|x|<em>p}}$，该范数通过向量的$L-p$范数定义，称为诱导范数（induced Norm），几何意义是矩阵所代表的线性变换对向量进行变换后，向量长度的最大拉伸倍数。<br><strong>谱范数（spectral norm）</strong>：$p&#x3D;2,\qquad\displaystyle{|W|&#x3D;\max</em>{x\neq0}\frac{|Wx|}{|x|}}$<br><strong>F范数（Frobenius norm）</strong>：$\displaystyle{|W|<em>F&#x3D;\sqrt{\sum</em>{i&#x3D;1}^m\sum</em>{j&#x3D;1}^n}w_{ij}^2}$，等价于向量的$L2$范数，将矩阵按行或列展开之后形成向量，然后计算$L2$范数。根据柯西不等式，对于任意$x$，$|Wx|\leq|W|_F\cdot|x|$。如果$x$为非零向量则F范数是谱范数的上界。</p><h3 id="2-2-6-线性变换"><a href="#2-2-6-线性变换" class="headerlink" title="2.2.6 线性变换"></a>2.2.6 线性变换</h3><p>矩阵与向量的乘法可以解释为线性变换（Linear transformation），它将一个向量变成另外一个向量。旋转变换是线性变换，其变换矩阵为正交矩阵；缩放变换是线性变换，其变换矩阵为对角矩阵。</p><h3 id="2-3-行列式"><a href="#2-3-行列式" class="headerlink" title="2.3 行列式"></a>2.3 行列式</h3><p>行列式（Determinant，det）是对矩阵的一种运算，它作用于<strong>方阵</strong>，将其映射成一个标量。</p><h4 id="2-3-1-行列式的定义与性质"><a href="#2-3-1-行列式的定义与性质" class="headerlink" title="2.3.1 行列式的定义与性质"></a>2.3.1 行列式的定义与性质</h4><p>$n$阶方阵$A$的行列式记为$|A|$或$det(A)$，称为$n$阶行列式，计算公式为：<br>$$|A|&#x3D;<br>\begin{vmatrix}<br>    a_{11}&amp;a_{12}&amp;\cdots&amp;a_{1n}\<br>    a_{21}&amp;a_{22}&amp;\cdots&amp;a_{2n}\<br>    \vdots&amp;\vdots&amp;\ddots&amp;\vdots\<br>    a_{n1}&amp;a_{n2}&amp;\cdots&amp;a_{nn}\<br>\end{vmatrix}<br>&#x3D;\sum_{j_1j_2\cdots j_n\in S_n}{(-1)^{\tau(j_1j_2\cdots j_n)}\prod_{i&#x3D;1}^n{a_{i,j_i}}}$$<br>其中$S_n$是$n$个正整数所有排列构成的集合，显然有$n!$种；$\tau(\cdot)$为排列的逆序数，排列中所有逆序的数量成为排列的逆序数。</p><p>行列式可以表示平行四边形与平行六面体的有向面积和体积，也是线性变换的伸缩因子。如果将方阵看做线性变换，则其行列式的绝对值表示该变换导致的体积元变化系数。</p><p><strong>拉普拉斯展开（Laplace Expansion）</strong>：一个行列式可以按照行或列进行递归展开。<br>$$|A|&#x3D;a_{i1}A_{i1}+a_{i2}A_{i2}+\cdots+a_{in}A_{in}&#x3D;a_{1j}A_{1j}+a_{2j}A_{2j}+\cdots+a_{nj}A_{nj}$$<br>其中$A_{ij}$是去掉矩阵$A$的第$i$行和第$j$列之后的$n-1$阶矩阵的行列式，并且带有符号$(-1)^{i+j}$。称$A_{ij}$为$a_{ij}$的代数余子式，不带符号的子行列式称为余子式。</p><ul><li>存在一行或一列全为0的行列式值为0，对角矩阵的行列式值为对角线元素的乘积，单位矩阵的行列式值为1，上三角或下三角矩阵的行列式值为主对角线元素的乘积。</li><li>行列式具有多线性，可以按照某行或某列的线性组合拆分成两个行列式之和；如果把某一行元素都乘以$k$，则行列式变为之前的$k$倍；矩阵与标量乘法的行列式为$|\alpha A|&#x3D;\alpha^n|A|$。</li><li>如果行列式的两行或列相等，那么行列式值为0。</li><li>如果$|A|\neq0$，则有$A\frac{1}{|A|}A^*&#x3D;I$，因此$A^{-1}&#x3D;\frac{1}{|A|}A^{<em>}$；这也证明了矩阵$A$可逆的充分必要条件是$|A|\neq0$，$A^</em>$为伴随矩阵。</li><li>如果矩阵$A$和$B$是尺寸相同的矩阵，则矩阵乘积的行列式等于行列式的乘积。</li></ul><h2 id="线性方程组"><a href="#线性方程组" class="headerlink" title="线性方程组"></a>线性方程组</h2><h3 id="2-4-1-高斯消元法"><a href="#2-4-1-高斯消元法" class="headerlink" title="2.4.1 高斯消元法"></a>2.4.1 高斯消元法</h3><p>Gaussian Elimination Method 通过将一个方程减掉另一个方程的倍数消除未知数，得到阶梯型方程组（利用初等变换将系数矩阵变成上三角矩阵）</p><h3 id="2-4-2-齐次方程组"><a href="#2-4-2-齐次方程组" class="headerlink" title="2.4.2 齐次方程组"></a>2.4.2 齐次方程组</h3><p>Homogeneous Linear Equations：齐次线性方程组是常数项为0的线性方程组，$Ax&#x3D;0$ 齐次方程一定有解 （$x&#x3D;0$）</p><ul><li>如果$r(A)&#x3D;n$，方程组只有<strong>0</strong>解</li><li>如果$r(A)&lt;n$，方程组有非<strong>0</strong>解</li><li>如果$A$是方阵，$r(A)&lt;n$等同于$A$不可逆</li><li>如果$x_1,\cdots,x_l$都是方程组的解，他们的任意组合$\sum_{i&#x3D;1}^l{k_ix_i}$也是方程组的解：$\displaystyle{A\left(\sum_{i&#x3D;1}^l{k_ix_i}\right)&#x3D;\sum_{i&#x3D;1}^lk_iAx_i&#x3D;\sum_{i&#x3D;1}^lk_i0&#x3D;0}$；如果这组解线性无关且方程组的任意一个解都可以由他们线性表示，则称他们为方程组的一个基础解系</li><li>如果$r(A)&lt;n$，则存在基础解系，且基础解系中包含$n-r(A)$个解</li></ul><p><strong>求解方法</strong><br>对系数矩阵进行初等变换，在得到自由未知数时，将其设为特殊值形成基础解系，然后得到方程组的通解。例如：<br>$<br>\begin{cases}<br>    x_1+2x_2+2x_3+x_4&#x3D;0\<br>    2x_1+x_2-2x_3-2x_4&#x3D;0\<br>    x_1-x_2-4x_3-3x_4&#x3D;0<br>\end{cases}<br>$ $\rightarrow$ $<br>\begin{array}{cccc}<br>    x_1&amp;x_2&amp;x_3&amp;x_4\<br>    \hline<br>    1&amp;0&amp;-2&amp;-5&#x2F;3\<br>    0&amp;1&amp;2&amp;4&#x2F;3\<br>    0&amp;0&amp;0&amp;0\<br>\end{array}$<br>令$x_3&#x3D;1,x_4&#x3D;0$，得基础解系的第一个解：$x_1&#x3D;(2,-2,1,0)^T$<br>令$x_3&#x3D;0,x_4&#x3D;1$，得基础解系的第二个解：$x_2&#x3D;(5&#x2F;3,-4&#x2F;3,0,1)^T$<br>方程组的通解为：$x&#x3D;k_1x_1+k_2x_2$，其中$k_1,k_2$为任意常数</p><h3 id="2-4-3-非齐次方程组"><a href="#2-4-3-非齐次方程组" class="headerlink" title="2.4.3 非齐次方程组"></a>2.4.3 非齐次方程组</h3><p>Non-homogeneous Linear Equations：常数项不全为0，$Ax&#x3D;b$，（利用初等变换将增广矩阵$B$变成上三角矩阵）</p><ul><li>如果$r(A)&#x3D;r(B)$，那么方程组的解存在</li><li>如果$r(A)&lt;r(B)$，那么方程组的解不存在</li><li>方程组有解的前提下，如果$r(A)&#x3D;n$，那么方程组有唯一解；如果$r(A)&lt;n$，那么方程组有无穷解</li><li>如果$x_1,\cdots,x_l$是非齐次方程组对应齐次方程组的基础解系，$x^*$是非齐次方程组的一个解，则$\sum_{i&#x3D;1}^l{k_ix_i+x^*}$是非齐次方程组的解</li></ul><p><strong>求解方法</strong><br>非齐次方程组的解为对应齐次方程组的通解加上非齐次方程组的一个特解（形如$x&#x3D;x^*+k_1x_1+k_2x_2$），特解可以任意选取，通常令自由未知数的值全为0。</p><blockquote><p>自由未知数：矩阵中元素全为0的行对应位置的未知数</p></blockquote><h2 id="2-5-特征值与特征向量-Eigenvalue-Eigenvector"><a href="#2-5-特征值与特征向量-Eigenvalue-Eigenvector" class="headerlink" title="2.5 特征值与特征向量 Eigenvalue Eigenvector"></a>2.5 特征值与特征向量 Eigenvalue Eigenvector</h2><h3 id="2-5-1-特征值与特征向量"><a href="#2-5-1-特征值与特征向量" class="headerlink" title="2.5.1 特征值与特征向量"></a>2.5.1 特征值与特征向量</h3><p>对于$n$阶矩阵$A$，其特征向量是经过这个矩阵的线性变换之后仍然处于同一条直线上的向量（$Ax&#x3D;\lambda x$），$\lambda$为特征值（是特征向量在矩阵的线性变换下的缩放比例），$x$为该特征值对应的特征向量，$A-\lambda I$为特征矩阵，$|A-\lambda I|&#x3D;0$为特征方程，特征方程对应的行列式展开之后是$\lambda$的$n$次多项式，称为矩阵的特征多项式。</p><ul><li>对角矩阵、上&#x2F;下三角矩阵的特征值为主对角线元素</li><li>根据多项式分解定理，特征方程可以写成$\displaystyle{(\lambda-\lambda_1)^{n_1}(\lambda-\lambda_2)^{n_2}\cdots(\lambda-\lambda_{N_\lambda})^{n_{N_\lambda}}&#x3D;0}$，其中$n_i$称为特征值$\lambda_i$的代数重数 Algebraic Multiplicity</li><li>所有$N_\lambda$个不同的特征值构成的集合称为<u>矩阵的谱 Spectrum</u>，其中特征值绝对值的最大值称为谱半径 Spectral Radius</li><li>求解方程组$(A-\lambda_i I)x&#x3D;0$得其特征向量，有$1\le m_i\le n_i$个线性无关解，称$m_i$为$\lambda_i$的几何重数 Geometric Multiplicity</li><li>这些线性无关的解构成的空间称为矩阵$A$关于特征值$\lambda_i$的特征子空间，记为$V_{\lambda_i}$，维数为$m_i&#x3D;n-r(A-\lambda_i I)$，<u>属于不同特征值的特征向量线性无关</u>，矩阵所有线性无关的特征向量的数量为$N_x&#x3D;\sum_{i&#x3D;1}^{N_\lambda}m_i$</li></ul><blockquote><p>阿贝尔-鲁菲尼（Abel-Ruffini）定理指出，4次以上的代数方程没有公式解。因此高阶矩阵的特征值只能求近似解，比起直接求解更好的办法是迭代法。</p></blockquote><p><strong>特征值与矩阵主对角线元素以及行列式的关系</strong></p><ul><li>矩阵的迹 Trace 定义为其主对角线元素之和：$tr(A)&#x3D;\sum_{i&#x3D;1}^n a_{ij}$</li><li>关于迹的公式：$tr(A+B)&#x3D;tr(A)+tr(B)\qquad tr(kA)&#x3D;k\cdot tr(A)\qquad tr(AB)&#x3D;tr(BA)$</li></ul><blockquote><p>根据韦达定理，$n$次方程：$x^n+c_{n-1}x^{n-1}+\cdots+c_1x+c_0&#x3D;0$ 所有根之和为：$x_1+x_2+\cdots+x_n&#x3D;-c_{n-1}$ 所有根的乘积为：$x_1x_2\cdots x_n&#x3D;(-1)^nc_0$</p></blockquote><ul><li>矩阵所有特征值的和为矩阵的迹：$\sum_{i&#x3D;1}^n\lambda_{i}&#x3D;tr(A)$</li><li>所有特征值的积为矩阵的行列式：$\prod_{i&#x3D;1}^n\lambda_{i}&#x3D;|A|$</li></ul><p><strong>特征值的重要性质</strong></p><ul><li>如果矩阵$A$可逆且$\lambda$为它的特征值，则$\lambda^{-1}$是$A^{-1}$的特征值</li><li>如果$\lambda$是$A$的特征值，则$\lambda^n$是$A^n$的特征值</li><li>如果$\lambda$是$A$的特征值，则$k\lambda$是$kA$的特征值</li><li>如果$\lambda$是$A$的特征值，则$f(\lambda)$是$f(A)$的特征值</li></ul><p><strong>特征向量的重要性质</strong></p><ul><li>如果一组向量是矩阵$A$关于同一个特征值$\lambda$的特征向量，则他们的非零组合仍是矩阵$A$关于$\lambda$的特征向量</li><li><u>实对称矩阵的特征值均为实数，属于不同特征值的特征向量相互正交</u></li></ul><p><strong>共轭矩阵</strong></p><ul><li>$A&#x3D;$ $\begin{pmatrix}<br>  1-i&amp;1\<br>  1&amp;1+i<br>\end{pmatrix}$ $\rightrightarrows$ $\overline{A}&#x3D;$ $\begin{pmatrix}<br>  1+i&amp;1\<br>  1&amp;1-i<br>\end{pmatrix}$</li><li>$\overline{A+B}&#x3D;\overline{A}+\overline{B}\qquad\overline{kA}&#x3D;k\overline{A}\qquad\overline{AB}&#x3D;\overline{A}\ \overline{B}\qquad\overline{(AB)^T}&#x3D;\overline{A}^T\ \overline{B}^T$</li></ul><h3 id="2-5-2-相似变换"><a href="#2-5-2-相似变换" class="headerlink" title="2.5.2 相似变换"></a>2.5.2 相似变换</h3><p>如果有两个矩阵$A$、$B$以及一个可逆矩阵$P$满足 $P^{-1}AP&#x3D;B$ 则称矩阵$A,B$相似，记为$A\sim B$，$P$为相似变换矩阵。<br>相似具有自反性（$A\sim{A}$）、对称性（$A\sim{B}\rightarrow B\sim{A}$）、传递性（$A\sim{B}, B\sim{C} \rightarrow A\sim{C}$）；相似矩阵有相同的特征值，意味着相似变换保持矩阵的特征值不变。<br><strong>矩阵的相似对角化</strong>：$P^{-1}AP&#x3D;\varLambda$ 可以以矩阵$A$的特征向量为列构造一个矩阵$P$，通过它将矩阵对角化，得到以$A$的特征值为主对角线的对角矩阵$\varLambda$。这种做法的成立条件是$P$可逆，即矩阵$A$有$n$个线性无关的特征向量。</p><h3 id="2-5-3-正交变换-（一种特殊的相似变换）"><a href="#2-5-3-正交变换-（一种特殊的相似变换）" class="headerlink" title="2.5.3 正交变换 （一种特殊的相似变换）"></a>2.5.3 正交变换 （一种特殊的相似变换）</h3><p>实对称矩阵一定可以对角化，我们可以构造一个正交的相似变换将其对角化。实对称矩阵属于不同特征值的特征向量是相互正交的，如果用格拉姆-施密特正交化将同一个特征值的所有向量正交化，然后将所有特征向量单位化，可以得到一组标准正交基。以它们构造相似变换矩阵。则矩阵是正交矩阵（满足$P^{-1}&#x3D;P^T$）。（$P^{T}AP&#x3D;\varLambda$）正交变换具有一个优良的性质，它可以保持矩阵的对称性。</p><blockquote><p>P的构造过程：求解矩阵A的所有特征向量，接着对其单位化，然后由这些向量组成矩阵P的列向量。</p></blockquote><p><strong>Householder变换：一种特殊的正交变换</strong><br>Householder矩阵：$P&#x3D;I-2\omega\omega^T&#x3D;I-\frac{uu^T}{H},H&#x3D;\frac{|u|^T}{2},u&#x3D;x\mp|x|e_1$，其中$\omega$是n维非0列向量且有$|\omega|&#x3D;1$，$u$为任意非0向量，$x$为n维列向量，$e_1&#x3D;(1,0,\cdots,0)^T$，显然$P$是对称矩阵且是正交矩阵。<br>$$Px&#x3D;(I-\frac{uu^T}{H})x&#x3D;x-\frac{u}{H}(x\mp|x|e_1)x&#x3D;x-\frac{2u(|x|^2\mp|x|x_1)}{2|x|^2\mp2|x|x_1}&#x3D;x-u&#x3D;\pm|x|e_1$$</p><ul><li>根据上式特性，我们可以构造以Housholder矩阵为基础的正交变换，将矩阵转化为类似对角矩阵的形式，零化主对角线之外的元素（左乘$P$零化第一列，右乘$P$零化第一行）。</li><li>如果是对称矩阵，通过$n-2$次豪斯霍德尔变换可以将$A$化为对称三角矩阵 Tridiagonal Matrix，这种矩阵除主对角线及其上下对角线的元素外，其他元素均为0。</li><li>如果是一般的实数矩阵，由于不对称右乘无法完全零化，通过$n-2$次豪斯霍德尔变换可以将$A$化为上海森堡矩阵 upper-Hessenberg form，这种矩阵除主对角线及其以上和主对角线下面的一条对角线的元素外，其他元素均为0。</li></ul><h3 id="2-5-4-QR算法"><a href="#2-5-4-QR算法" class="headerlink" title="2.5.4 QR算法"></a>2.5.4 QR算法</h3><p><strong>QR分解</strong>：对于一个矩阵$A$，QR分解将其转化为一个正交矩阵$Q$与一个上三角矩阵$R$的乘积。<br><strong>QR算法</strong>：一种迭代算法，从矩阵$A_0&#x3D;A$开始，每次构造一个相似变换，将$A_{k-1}$变换成$A_k$，最后$A_k$收敛到一个上三角矩阵，主对角线元素即为其特征值。<br><strong>QR迭代</strong>:$A_k&#x3D;Q_kR_k\rightarrow A_{k+1}&#x3D;R_kQ_k$，对于实对称矩阵$A$，QR迭代产生的所有正交矩阵$Q_k$的乘积的所有列列为$A$的特征向量。<br><strong>加快收敛速度</strong>：<br>1、带位移的QR算法，迭代公式为$A_k-s_kI&#x3D;Q_kR_k\rightarrow A_{k+1}&#x3D;R_kQ_k+s_kI$<br>2、Householder变换将$A$化成三角矩阵</p><h3 id="2-5-5-广义特征值"><a href="#2-5-5-广义特征值" class="headerlink" title="2.5.5 广义特征值"></a>2.5.5 广义特征值</h3><p>Generalized Eigenvalue 是特征值的推广，定义于两个矩阵之上，对于方阵$A$和$B$，如果存在一个数$\lambda$及非<strong>0</strong>向量$x$，满足$Ax&#x3D;\lambda Bx$，则称$\lambda$为广义特征值，$x$为广义特征向量；如果矩阵$B$可逆，则$B^{-1}Ax&#x3D;\lambda x$，广义特征值在机器学习中被广泛应用，包括流形学习、谱聚类算法、以及线性判别分析等。</p><h3 id="2-5-6-瑞利商-Rayleigh-Quotient"><a href="#2-5-6-瑞利商-Rayleigh-Quotient" class="headerlink" title="2.5.6 瑞利商 Rayleigh Quotient"></a>2.5.6 瑞利商 Rayleigh Quotient</h3><ul><li>$\displaystyle{R(A,x)&#x3D;\frac{x^TAx}{x^Tx}}$：定义为方阵$A$和非<strong>0</strong>向量$x$的瑞利商，对于任意的非0实数$k$，有$R(A,kx)&#x3D;R(A,x)$，即对向量缩放之后其瑞利商不变，瑞利商存在冗余。</li><li>$x^Tx&#x3D;1$：增加约束确保解的唯一性，消除冗余。</li><li>$\lambda_{min}\le R(A,x)\le\lambda_{max}$：瑞利商的所有极值在矩阵的特征值与特征向量处取得（拉格朗日乘数法证明），在最大特征值处，瑞利商有最大值，最小特征值处有最小值。（其典型应用是主成分分析）</li><li>$\displaystyle{R(A,B,x)&#x3D;\frac{x^TAx}{x^TBx}}$：广义瑞利商的性质和瑞利商基本一致，存在冗余，将向量$x$缩放后瑞利商不变；可以增加约束消除冗余$x^TBx&#x3D;1$。</li><li>$\displaystyle{\frac{x^TAx}{x^TBx}&#x3D;\frac{((C^T)^{-1}y)^TA((C^T)^{-1}y)}{((C^T)^{-1}y)^TCC^T((C^T)^{-1}y)}&#x3D;\frac{y^TC^{-1}A(C^T)^{-1}y}{y^Ty}}$：如果令$B&#x3D;CC^T$（对矩阵$B$的楚列斯基Cholesky分解），$x&#x3D;(C^T)^{-1}y$，则可以将广义瑞利商转化为瑞利商。（线性判别分析的优化目标函数就是广义瑞利商）</li></ul><h3 id="2-5-7-谱范数与特征值的关系"><a href="#2-5-7-谱范数与特征值的关系" class="headerlink" title="2.5.7 谱范数与特征值的关系"></a>2.5.7 谱范数与特征值的关系</h3><p>矩阵$W$的谱范数等于的$W^TW$最大特征值的平方根，即$W$最大的奇异值</p><p>（$|W|_2&#x3D;\max{[\sigma_1, \cdots, \sigma_n]}$）；</p><p>谱范数的平方为瑞利商的最大值（$\displaystyle{|W|<em>2^2&#x3D;\max</em>{x\ne0}&#x3D;\frac{x^TW^TWx}{x^Tx}}$）。</p><h3 id="2-5-8-条件数"><a href="#2-5-8-条件数" class="headerlink" title="2.5.8 条件数"></a>2.5.8 条件数</h3><p>如果矩阵$W$可逆，条件数定义为它的范数与它的逆矩阵范数的乘积（可以是任意范数），$cond(W)&#x3D;|W|\cdot|W^{-1}|$。条件数总是大于等于1的，它决定了矩阵的稳定性，条件数越大则矩阵越接近不可逆矩阵，矩阵越ill-posed。如果使用谱范数，则条件数等于矩阵的最大奇异值与最小奇异值的比值。</p><h3 id="2-5-9-应用——谱归一化与谱正则化"><a href="#2-5-9-应用——谱归一化与谱正则化" class="headerlink" title="2.5.9 应用——谱归一化与谱正则化"></a>2.5.9 应用——谱归一化与谱正则化</h3><blockquote><p><strong>谱正则化 Spectral Regularization</strong>：正则化是机器学习中减轻过拟合的技术，它迫使模型的参数值很小，是模型变得更简单（一般地，简单的模型有更好的泛化性能，奥卡姆剃刀？）。谱正则化用谱范数构造正则项。<br><strong>谱归一化 Spectral Normalization</strong>：通过谱范数对线性映射的矩阵进行谱归一化来确保映射有较小的利普希茨常数，从而保证机器学习模型对输入数据的扰动不敏感。</p></blockquote><p><code>示例</code> 神经网络$f(x)&#x3D;Wx+b$ 如果映射满足Lipschitz条件（将其推广到多元函数，绝对值改为向量的范数），则有$|Wx_1+b-Wx_2+b|&#x3D;|Wx_1-Wx_2|\le K|x_1-x_2|$，假设权重矩阵的谱范数为$\sigma(W)$，归一化后$W_{SN}&#x3D;W&#x2F;\sigma(W)$，然后用谱范数做正则项有目标函数：<br>$$\frac{1}{N}\sum_{i&#x3D;1}^N{L(x_i,y_i)}+\frac{\lambda}{2}\sum_{i&#x3D;1}^l{\sigma(W_i)^2}$$<br>其中$L(x_i,y_i)$为单样本损失函数，为神经网络层数，为对应层权重矩阵；谱正则项由神经网络所有层权重矩阵的谱范数平方和构成，可以防止权重矩阵出现大的谱范数，从而保证神经网络的映射有较小的Lipschitz常数。</p><h2 id="2-6-二次型"><a href="#2-6-二次型" class="headerlink" title="2.6 二次型"></a>2.6 二次型</h2><p>二次型是一种特殊的二次函数，只含有二次项。</p><h3 id="2-6-1-基本概念"><a href="#2-6-1-基本概念" class="headerlink" title="2.6.1 基本概念"></a>2.6.1 基本概念</h3><ul><li>Quadric Form 二次型是由纯二次项构成的函数，即二次齐次多项式，可以写成矩阵形式：$x^TAx$，其中$A$是$n$阶对称矩阵，$x$是一个列向量。</li><li>二次型对应的矩阵：平方项$ax^2$的系数是矩阵的主对角线元素，交叉乘积项$ax_ix_j$的系数由$a_{ij}$与$a_{ji}$均分。<code>实对称矩阵与二次型一一对应</code></li></ul><p><code>示例</code> 二次型 $2x^2-3xy+y^2+z^2$ 对应的矩阵为 $\begin{pmatrix}<br>    2&amp;-1.5&amp;0\<br>    -1.5&amp;1&amp;0\<br>    0&amp;0&amp;1\<br>\end{pmatrix}$</p><h3 id="2-6-2-正定二次型与正定矩阵"><a href="#2-6-2-正定二次型与正定矩阵" class="headerlink" title="2.6.2 正定二次型与正定矩阵"></a>2.6.2 正定二次型与正定矩阵</h3><p>如果一个二次型对于任意非<strong>0</strong>向量$x$都有$x^TAx&gt;0$，则称该二次型为正定（Positive Definite）二次型，矩阵$A$为正定矩阵；如果对于任意非<strong>0</strong>向量$x$都有$x^TAx\ge0$，则称该二次型为半正定（Positive Semi-definite）二次型，矩阵$A$为半正定矩阵；对于任意非<strong>0</strong>向量$x$都有$x^TAx&lt;0$，则称该二次型为负定（Negative Definite）二次型，矩阵$A$为负定矩阵，类似地可以定义半负定；如果不正定也不负定就称为不定。<code>正定二次型被用于多元函数极值的判定法则</code> <code>正定矩阵所有主对角线元素大于0</code></p><p>证明对称矩阵$A$正定可以按照定义进行，也可以：</p><ol><li>矩阵$A$的$n$个特征值$\lambda_1,\cdots,\lambda_n$均大于0：通过正交变换将二次型华为标准型证明。</li><li>存在可逆矩阵$P$使得$A&#x3D;P^TP$：因为可逆，任意非0向量$x$有$Px\neq0$，$x^TAx&#x3D;x^TP^TPx&#x3D;(Px)^T(Px)&gt;0$</li><li>如果$A$是正定矩阵，则$A^T$也是正定矩阵：$(x^TA^Tx)^T&#x3D;x^TAx&gt;0$</li><li>矩阵$A$的所有顺序主子式均为正：顺序主子式是矩阵左上角的子方阵形成的行列式</li></ol><p>对于任意的$m\times n$矩阵$A$，$A^TA$是对称半正定矩阵，$AA^T$也是对称半正定矩阵。</p><p>实对称负定：</p><ol><li>矩阵$A$的$n$个特征值$\lambda_1,\cdots,\lambda_n$均小于0</li><li>存在可逆矩阵$P$使得$A&#x3D;-P^TP$</li><li>矩阵$A$的所有奇数顺序主子式均为负，偶数顺序主子式均为正</li></ol><h3 id="2-6-3-标准型"><a href="#2-6-3-标准型" class="headerlink" title="2.6.3 标准型"></a>2.6.3 标准型</h3><p>标准型指对于任意的$i\neq j$，二次型中项$a_{ij}x_ix_j$的系数均为0，二次型由纯平方项构成，形如 $x^TAx&#x3D;d_1x_1^2+\cdots+d_nx_n^2$。<code>标准型对应的矩阵为对角矩阵</code> 在标准型中，正平方项的个数称为正惯性指数，负平方项的数量为负惯性指数。 <code>二次型的矩阵为对称矩阵，因此一定可以对角化</code> 对于二次型$x^TAx$，通过<strong>正交变换</strong>将$A$化为对角矩阵$A&#x3D;P\Lambda P^T$，从而有$x^TAx&#x3D;x^TP\Lambda P^Tx&#x3D;(P^Tx)^T\Lambda(P^Tx)$，$P$是正交矩阵，如果令$y&#x3D;P^Tx$，则$y^T\Lambda y$是标准型。</p><h2 id="2-7-矩阵分解"><a href="#2-7-矩阵分解" class="headerlink" title="2.7 矩阵分解"></a>2.7 矩阵分解</h2><h3 id="2-7-1-楚列斯基分解Cholesky"><a href="#2-7-1-楚列斯基分解Cholesky" class="headerlink" title="2.7.1 楚列斯基分解Cholesky"></a>2.7.1 楚列斯基分解Cholesky</h3><p>对于$n$阶<strong>对称半正定矩阵</strong>$A$，Cholesky分解将其分解为$n$阶<strong>下三角矩阵</strong>$L$以及其转置的乘积：$A&#x3D;LL^T$。如果$A$是实对称正定矩阵，则分解唯一。<strong>Cholesky分解还可以用于检查矩阵的正定性</strong>，如果一个矩阵不能进行Cholesky分解则说明矩阵不是半正定矩阵，否则为半正定矩阵。</p><h3 id="2-7-2-QR分解"><a href="#2-7-2-QR分解" class="headerlink" title="2.7.2 QR分解"></a>2.7.2 QR分解</h3><p>QR分解（正交三角分解）将矩阵$A$分解为<strong>正交矩阵</strong>$Q$与上三角矩阵$R$的乘积，<code>QR分解是格拉姆-施密特正交化的另外一种表现形式</code>。</p><ol><li>对于任意$n$阶方阵：$A&#x3D;QR$</li><li>对于非方阵，$m&gt;n$：$A&#x3D;QR&#x3D;Q\begin{pmatrix}R_n \ 0_{(m-n)\times n}\end{pmatrix}$</li><li>对于非方阵，$m&lt;n$：$A&#x3D;QR&#x3D;Q\begin{pmatrix}R_m&amp;B_{m\times(n-m)}\end{pmatrix}$，$B$是一个$m\times(n-m)$的矩阵</li><li>QR分解的三种实现方式：格拉姆-施密特正交化、豪斯霍尔德变换、吉文斯旋转</li></ol><h3 id="2-7-3-特征值分解"><a href="#2-7-3-特征值分解" class="headerlink" title="2.7.3 特征值分解"></a>2.7.3 特征值分解</h3><p>又称为<strong>谱分解</strong>，是<strong>矩阵相似对角化</strong>的另一种表现形式，对于$n$阶<strong>方阵</strong>$A$，如果它有$n$个线性无关的特征向量，则可将其分解为：$A&#x3D;Q\varLambda Q^{-1}$。</p><ol><li>其中$\varLambda$为对角矩阵，对角线元素是$A$的特征值；$Q$的列为$A$的特征向量</li><li>分解充分必要条件：它有$n$个线性无关的特征向量</li><li>如果$A$可以进行特征值分解，且所有特征值都非0，则$A^{-1}&#x3D;Q\varLambda^{-1}Q^{-1}$</li><li>如果$A$可以进行特征值分解，则$f(A)&#x3D;Qf(\varLambda)Q^{-1}$</li></ol><h3 id="2-7-4-奇异值分解SVD"><a href="#2-7-4-奇异值分解SVD" class="headerlink" title="2.7.4 奇异值分解SVD"></a>2.7.4 奇异值分解SVD</h3><p>SVD是特征值分解的推广（思路是对$AA^T$和$A^TA$进行特征值分解），对于任意矩阵均可用特征值与特征向量进行分解：$A&#x3D;U\Sigma V^T$</p><ol><li>$U$为$m$阶正交矩阵，其列为矩阵$A$的左奇异向量，也是$AA^T$的特征向量</li><li>$\Sigma$为$A$的奇异值，是$AA^T$特征值的非负平方根，也是$A^TA$特征值的非负平方根</li><li>$V$为$n$阶正交矩阵，其列为矩阵$A$的右奇异向量，也是$A^TA$的特征向量</li></ol><p><strong>几何意义</strong><br>向量左乘任意矩阵所实现的线性变换可以分解成三次变换$Ax&#x3D;U\Sigma V^Tx$：首先是$V^T$代表的旋转变换，接着是$\Sigma$代表的拉伸变换，最后是$U$代表的旋转变换。</p>]]></content>
      
      
      <categories>
          
          <category> 《机器学习的数学》-雷明 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 学习笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>电脑系统使用过程中常见问题记录</title>
      <link href="/2022/10/03/System-skills/"/>
      <url>/2022/10/03/System-skills/</url>
      
        <content type="html"><![CDATA[<blockquote><p>记录Windows、Linux系统在日常使用中遇到的问题</p></blockquote><span id="more"></span><h1 id="Linux系统"><a href="#Linux系统" class="headerlink" title="Linux系统"></a>Linux系统</h1><h2 id="Ubuntu修改主机名"><a href="#Ubuntu修改主机名" class="headerlink" title="Ubuntu修改主机名"></a>Ubuntu修改主机名</h2><pre><code class="bash"># 查看主机名hostname# 修改主机名# 1.主机名存放在/etc/hostname文件vim /etc/hostname# 2.修改host域名映射vim /etc/hosts# 3.重启系统reboot</code></pre><blockquote><p>查看操作系统<br>cat &#x2F;proc&#x2F;version<br>uname -a<br>cat &#x2F;etc&#x2F;issue</p></blockquote><pre><code class="bash"># 查看主板信息sudo dmidecode --type baseboard# 查看CPUsudo dmidecode --type processor# 查看内存信息sudo dmidecode --type memory # 查看显卡nvtop# 查看硬盘sudo lsblk -e7sudo lsblk -d -o name,rota# 查看指定应用的进程pidpgrep -l [server_name]</code></pre><h2 id="设置root密码"><a href="#设置root密码" class="headerlink" title="设置root密码"></a>设置root密码</h2><pre><code class="bash">sudo passwd</code></pre><h2 id="改变Ubuntu命令行前缀"><a href="#改变Ubuntu命令行前缀" class="headerlink" title="改变Ubuntu命令行前缀"></a>改变Ubuntu命令行前缀</h2><pre><code class="bash"># 修改~/.bashrc文件中的PS1$&#123;debian_chroot:+($debian_chroot)&#125;\u@\h:\w\$# 主要信息# \u 当前登录用户名 # \h 当前计算机名称（譬如ubuntu） # \H 当前计算机的域名全程，譬如（ubuntu.ubuntu.com) # \w 当前目录 # \W 当前目录的basename # \$ 一般用户为$，root用户为&gt; # 时间显示 # \t 当前时间（24小时制，HH:MM:SS 分别代表 小时：分钟：秒） # \T 当前时间（12小时制） # \@ 当前时间（AM/PM显示） # \d 当前日期 # Shell信息： # \v Bash版本 # \V Bash的发布版本号 # \S Shell名称 # \! Bash命令的历史编号 # \j job序号 # \l Shell的终端名称PS1=&quot;\[\e]0;$&#123;debian_chroot:+($debian_chroot)&#125;shell@ubuntu: \w\a\]$PS1&quot;# 修改生效source ~/.bashrc# 改变立即生效，命令提示符将变成固定的格式：shell@ubuntu:~$</code></pre><h2 id="Linux命令行只显示一个提示符-，键盘方向键无效"><a href="#Linux命令行只显示一个提示符-，键盘方向键无效" class="headerlink" title="Linux命令行只显示一个提示符$，键盘方向键无效"></a>Linux命令行只显示一个提示符$，键盘方向键无效</h2><pre><code class="bash"># 1.进入bash模式bash# 2.输入chshchsh# 3.在Login Shell [*]后面输入/bin/bash</code></pre><h2 id="Ubuntu配置固定IP"><a href="#Ubuntu配置固定IP" class="headerlink" title="Ubuntu配置固定IP"></a>Ubuntu配置固定IP</h2><blockquote><p>Ubuntu从17.10开始放弃在&#x2F;etc&#x2F;network&#x2F;interfaces里面配置IP，改为在&#x2F;etc&#x2F;netplan&#x2F;XX-installer-config.yaml中配置</p></blockquote><pre><code class="bash"># 查看网络配置信息ip addr# 编辑XX-installer-config.yaml文件sudo vim /etc/netplan/00-installer-config.yaml# 配置完成后，生效配置sudo netplan apply</code></pre><p><code>XX-installer-config.yaml</code>修改内容如下</p><pre><code class="yaml"># This is the network config written by &#39;subiquity&#39;network:  ethernets:    enp8s0:                             # 配置网卡的名称      addresses: [192.168.1.149/24]     # 配置的静态IP地址和掩码      dhcp4: false                      # 关闭dhcp      optional: true      gateway4: 192.168.1.1             # 网关地址      nameservers:                      # 配置DNS服务器地址，多个使用英文逗号&lt;,&gt;隔开，可不配置        addresses: [192.168.1.1,114.114.114.114]  version: 2</code></pre><h2 id="给用户添加sudo权限"><a href="#给用户添加sudo权限" class="headerlink" title="给用户添加sudo权限"></a>给用户添加sudo权限</h2><pre><code class="bash"># 1.直接修改配置文件，该文件是给用户组赋予权限的vim /etc/sudoers# 在文本中添加一行: sudo权限且免密group_name  ALL=(ALL)  NOPASSWD:ALL  # 2.将用户拉入sudo组sudo usermod -aG sudo &quot;username&quot;  # method.1sudo gpasswd -a user_name group_name  # method.2sudo gpasswd -d user_name group_name  # 从组中删除用户</code></pre><h2 id="shutdown命令"><a href="#shutdown命令" class="headerlink" title="shutdown命令"></a>shutdown命令</h2><pre><code class="bash"># 句法 syntaxshutdown [-t seconds] [-rkhncfF] time [message]# 参数说明# -t seconds : 设定在几秒钟之后进行关机程序。# -k : 并不会真的关机，只是将警告讯息传送给所有使用者。# -r : 关机后重新开机。# -h : 关机后停机。# -n : 不采用正常程序来关机，用强迫的方式杀掉所有执行中的程序后自行关机。# -c : 取消目前已经进行中的关机动作。# -f : 关机时，不做 fsck 动作(检查 Linux 档系统)。# -F : 关机时，强迫进行 fsck 动作。# time : 设定关机的时间。# message : 传送给所有使用者的警告讯息。# 关机shutdownshutdown -h nowshutdown -h 5     # 5分钟后关机shutdown 5 &quot;This system will shutdown in 5 minutes&quot;# 重启rebootshutdown -rshutdown -r 10    # 10分钟后重启shutdown -r -f    # 重启时跳过文件系统检查（fsck）</code></pre><h2 id="添加路由映射"><a href="#添加路由映射" class="headerlink" title="添加路由映射"></a>添加路由映射</h2><pre><code class="bash"># 打印路由表netstat -rn     # 添加路由映射sudo ip route add 10.23.242.0/24 via 222.28.47.1 dev enp5s0</code></pre><h2 id="创建用户"><a href="#创建用户" class="headerlink" title="创建用户"></a>创建用户</h2><pre><code class="bash"># adduser[deluser]: 自动创建用户的指定主目录、系统shell版本、用户密码# useradd[userdel]: 需要配合参数完成上述配置adduser [username]  # 用户主目录默认为`/home/$&#123;用户名&#125;`, shell默认为`/bin/bash`</code></pre><h2 id="systemctl命令"><a href="#systemctl命令" class="headerlink" title="systemctl命令"></a>systemctl命令</h2><p>为系统的启动和管理提供一套完整的解决方案，XXX对应应用名称</p><pre><code class="bash"># 重启系统sudo systemctl reboot# 关闭系统，切断电源sudo systemctl poweroff# CPU停止工作sudo systemctl halt# 暂停系统sudo systemctl suspend# 让系统进入冬眠状态sudo systemctl hibernate# 让系统进入交互式休眠状态sudo systemctl hybrid-sleep# 启动进入救援状态（单用户状态）sudo systemctl rescuesudo systemctl start XXXsudo systemctl restart XXXsudo systemctl stop XXXsudo systemctl status XXX</code></pre><h1 id="Windows系统"><a href="#Windows系统" class="headerlink" title="Windows系统"></a>Windows系统</h1><h2 id="重装系统（U盘启动器版）"><a href="#重装系统（U盘启动器版）" class="headerlink" title="重装系统（U盘启动器版）"></a>重装系统（U盘启动器版）</h2><h3 id="制作U盘启动器"><a href="#制作U盘启动器" class="headerlink" title="制作U盘启动器"></a>制作U盘启动器</h3><blockquote><ol><li>在软碟通UltraISO顶部菜单中点击<code>文件-&gt;打开-&gt;下载好的系统ISO文件</code></li><li>在软碟通UltraISO顶部菜单中点击<code>启动-&gt;写入硬盘映像</code></li><li>选择待写入U盘，默认设置，点击<code>写入</code>，等待完成</li></ol></blockquote><h3 id="系统设置U盘启动项"><a href="#系统设置U盘启动项" class="headerlink" title="系统设置U盘启动项"></a>系统设置U盘启动项</h3><p><strong>方法一</strong></p><blockquote><ol><li>开机，按<code>F12</code>进入<code>启动设备菜单窗口</code></li><li>插入U盘选择<code>USB key</code>回车进入U盘启动模式 (一般到这就OK了，后续操作因BIOS版本不同而异)</li><li>在<code>启动设备菜单窗口</code>选择<code>Enter Setup</code>进入BIOS设置</li><li>进入BIOS选择<code>Startup-&gt;Primary Root Sequence</code>将USB设为第一个</li><li><code>Exit-&gt;Save changes and exit</code></li></ol></blockquote><p><strong>方法二</strong></p><blockquote><ol><li>进入BIOS，记住底部操作快捷键</li><li>在<code>boot-&gt;boot device priority</code>中找到U盘选项，按<code>+</code>实现向上移动，直到最上面</li><li>按<code>F10-&gt;yes</code>保存</li></ol></blockquote><h2 id="磁盘管理"><a href="#磁盘管理" class="headerlink" title="磁盘管理"></a>磁盘管理</h2><h3 id="C盘扩容"><a href="#C盘扩容" class="headerlink" title="C盘扩容"></a>C盘扩容</h3><p><strong>方法一：重新分配</strong></p><blockquote><p>假设：C盘100G，D盘100G<br>D盘数据备份-&gt;删除卷-&gt;得到100G未分配空间<br>C盘-&gt;扩展卷<br>D盘-&gt;新建简单卷</p></blockquote><p><strong>方法二：压缩分配</strong></p><blockquote><p>假设：C盘100G，D盘100G<br>D盘-&gt;压缩卷<br>C盘-&gt;扩展卷</p></blockquote><h2 id="自带的磁盘管理diskpart命令"><a href="#自带的磁盘管理diskpart命令" class="headerlink" title="自带的磁盘管理diskpart命令"></a>自带的磁盘管理diskpart命令</h2><pre><code class="bash"># 启动diskpartdiskpart# 列出所有硬盘list disk# 选择要操作的硬盘select disk 0# 清除硬盘clean# 创建主分区create partition primary size=20480 # 创建20G的主分区active        # 激活主分区format quick  # 快速格式化主分区# 创建扩展分区create partition extended             # 剩余磁盘空间全部作为扩展分区create partition logical size=15360   # 创建15G的逻辑分区create partition logical              # 剩余空间全部作为逻辑分区# 分区完毕，退出exit</code></pre>]]></content>
      
      
      <categories>
          
          <category> Using Skills </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Sys.log </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LaTex写作实用技巧</title>
      <link href="/2022/08/17/LaTex-usetech/"/>
      <url>/2022/08/17/LaTex-usetech/</url>
      
        <content type="html"><![CDATA[<h3 id="multicolumn多列合并导致表格横线不显示"><a href="#multicolumn多列合并导致表格横线不显示" class="headerlink" title="\multicolumn多列合并导致表格横线不显示"></a>\multicolumn多列合并导致表格横线不显示</h3><p>两种解决方法</p><blockquote><ol><li>增加一个宽度为0的列</li><li><code>\vline</code>：由于线的粗细不同，补的横线并不是完美对齐</li></ol></blockquote><span id="more"></span><h3 id="Elsevier模板使用"><a href="#Elsevier模板使用" class="headerlink" title="Elsevier模板使用"></a>Elsevier模板使用</h3><p><strong>添加标题</strong></p><pre><code class="latex">\title[mode=title]&#123;标题，默认设置&#125;\title[mode=alt]&#123;备用标题&#125;\title[mode=sub]&#123;副标题&#125;\title[mode=trans]&#123;翻译标题&#125;\title[mode=transub]&#123;翻译副标题&#125;</code></pre><p><strong>作者信息相关</strong></p><pre><code class="latex">\author[label1]&#123;姓名 \corref&#123;cor1&#125;&#125;\ead&#123;XXX@XXX.com&#125;\address[label1]&#123;地址&#125;\cortext[cor1]&#123;Corresponding author&#125;</code></pre><blockquote><p>只给出最常用🌰<br>更丰富使用技巧请看参考链接</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> Using Skills </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LaTeX </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>第1章 一元函数微积分</title>
      <link href="/2022/06/21/Learning-MathematicsOfMachineLearning-chap1/"/>
      <url>/2022/06/21/Learning-MathematicsOfMachineLearning-chap1/</url>
      
        <content type="html"><![CDATA[<blockquote><p>微分学为研究函数的性质提供了统一的方法与理论，尤其是寻找函数的极值。积分则在机器学习中被用于计算某些概率分布的数字特征。</p></blockquote><span id="more"></span><h2 id="1-1-极限与连续"><a href="#1-1-极限与连续" class="headerlink" title="1.1 极限与连续"></a>1.1 极限与连续</h2><h3 id="1-1-1-可数集与不可数集"><a href="#1-1-1-可数集与不可数集" class="headerlink" title="1.1.1 可数集与不可数集"></a>1.1.1 可数集与不可数集</h3><ul><li>集合$A$的元素数量称为其<strong>基数或者势</strong>，记为$|A|$。</li><li>对于集合$A$和$B$，如果集合$A$中的任意元素$a$，在集合$B$中都有唯一的元素$b$通过某种映射关系与之对应，即存在如下<strong>双射函数</strong>（Bijection， 一对一映射函数）:$$b&#x3D;f(a),a\in A, b\in B$$则称这两个集合的基数相等。（例如，实数集$\mathbb{R}$与区间$[0,1]$是等价的）</li><li>无限集可进一步分为可数集（Countable set）与不可数集（Uncountable set），可数集中的每个元素可以用正整数进行编号。<strong>离散与可数等价</strong>，任意可数集在数轴上的“长度”为0，不可数集长度不为0的在数轴上是稠密或是连续的，<strong>连续与不可数等价</strong>。</li></ul><h3 id="1-1-2-数列的极限"><a href="#1-1-2-数列的极限" class="headerlink" title="1.1.2 数列的极限"></a>1.1.2 数列的极限</h3><ul><li>数列极限的四则运算：$$\begin{align}<br>  \lim_{n\rightarrow+\infty}(a_n \plusmn b_n)&amp;&#x3D;\lim_{n\rightarrow+\infty}{a_n}\plusmn\lim_{n\rightarrow+\infty}{b_n}\<br>  \lim_{n\rightarrow+\infty}(a_n \cdot b_n)&amp;&#x3D;\lim_{n\rightarrow+\infty}{a_n}\cdot\lim_{n\rightarrow+\infty}{b_n}\<br>  \lim_{n\rightarrow+\infty}(\frac{a_n}{b_n})&amp;&#x3D;\frac{\lim_{n\rightarrow+\infty}{a_n}}{\lim_{n\rightarrow+\infty}{b_n}}<br>\end{align}$$</li><li>数列的上下界：上界$a_n\leq U$不唯一，下界$an\geq L$。单调有界的数列收敛，此称为<strong>单调收敛定理</strong>。有界是数列收敛的必要条件而非充分条件，如果数列无界，则必定发散。</li><li><strong>夹逼定理</strong>：如果对于$\forall n\in\mathbb{N}$有$b_n\leq a_n\leq c_n$且$\displaystyle{\lim_{n\rightarrow+\infty}{b_n}&#x3D;\lim_{n\rightarrow+\infty}{c_n}&#x3D;c}$，则$\displaystyle{\lim_{n\rightarrow+\infty}{a_n}&#x3D;c}$。</li></ul><h3 id="1-1-3-函数的极限"><a href="#1-1-3-函数的极限" class="headerlink" title="1.1.3 函数的极限"></a>1.1.3 函数的极限</h3><ul><li>极限是由柯西给出的$\epsilon-\delta$定义，其中点$x_0$的$\delta$邻域是指满足不等式$|x-x_0|\lt\delta$的所有$x$的集合，$\delta$为邻域半径。</li><li>函数在某一点极限存在的条件是在该点处的左右极限均存在且相等。</li></ul><h3 id="1-1-4-函数的连续性与间断点"><a href="#1-1-4-函数的连续性与间断点" class="headerlink" title="1.1.4 函数的连续性与间断点"></a>1.1.4 函数的连续性与间断点</h3><ul><li>第一类间断点：$x_0$处左右极限存在，但不相等，$f(x_0^-)\neq{f(x_0^+)}$为跳跃间断点；$x_0$处左右极限相等，但不等于该点处的函数值，$f(x_0^-)&#x3D;f(x_0^+)\neq{f(x_0)}$为可去间断点。</li><li>第二类间断点：$x_0$处左极限或右极限至少有一个不存在。</li><li>介值定理：如果函数$f(x)$在闭区间$[a,b]$内连续，$c$是介于$f(a)$和$f(b)$之间的数，则存在$[a,b]$中某点$x$，使得$f(x)&#x3D;c$。</li></ul><h3 id="1-1-5-上确界与下确界"><a href="#1-1-5-上确界与下确界" class="headerlink" title="1.1.5 上确界与下确界"></a>1.1.5 上确界与下确界</h3><ul><li>上确界（Supremum，最小上界，$s\leq{t}$，记为$sup(S)$，<strong>存在则唯一</strong>）和下确界（Infimum，最大下界，$s\geq{t}$，记为$inf(S)$）可看作是集合最大值和最小值的推广。</li></ul><h3 id="1-1-6-利普希茨连续性"><a href="#1-1-6-利普希茨连续性" class="headerlink" title="1.1.6 利普希茨连续性"></a>1.1.6 利普希茨连续性</h3><ul><li>Lipschitz连续不但保证函数值不间断，还限定函数变化速度：给定函数$f(x)$，如果对于区间$D$内任意两点$a$、$b$都存在常数K使得$$|f(a)-f(b)|\leq{K|a-b|}$$则称函数在区间内满足利普希茨条件&#x2F;连续。如果$K\lt1$，则称函数为压缩映射。</li><li>Lipschitz连续要求函数在区间上不能有超过线性的变化速度，对于分析和确保机器学习算法的稳定性有重要作用。</li></ul><h3 id="1-1-7-无穷小量"><a href="#1-1-7-无穷小量" class="headerlink" title="1.1.7 无穷小量"></a>1.1.7 无穷小量</h3><p>假设$f(x)$和$g(x)$都是$x\rightarrow{x_0}$的无穷小量（极限为0）：</p><ul><li>$\displaystyle{\lim_{x\rightarrow{x_0}}{\frac{f(x)}{g(x)}&#x3D;0}}$，该比值也是无穷小量，$f(x)$为$g(x)$的高阶无穷小，记为$f(x)&#x3D;o(g(x))$。</li><li>$\displaystyle{\lim_{x\rightarrow{x_0}}{\frac{f(x)}{g(x)}&#x3D;c,c\neq0}}$，该比值的极限为非0有界变量，等价无穷小，记为$f(x)\sim g(x)$。</li><li>$\displaystyle{\lim_{x\rightarrow{x_0}}{\frac{f(x)}{g(x)}&#x3D;\infty}}$，该比值的极限为无界变量，低阶无穷小。</li><li>这些比值反映了无穷小量趋向于0的速度快慢。</li></ul><h2 id="1-2-导数与微分"><a href="#1-2-导数与微分" class="headerlink" title="1.2 导数与微分"></a>1.2 导数与微分</h2><h3 id="1-2-1-一阶导数"><a href="#1-2-1-一阶导数" class="headerlink" title="1.2.1 一阶导数"></a>1.2.1 一阶导数</h3><ul><li>导数的定义为函数的自变量变化值趋向于0时，函数变化量与自变量变化之间的比值：$$f^\prime(x)&#x3D;\displaystyle{\lim_{\Delta x\rightarrow0}{\frac{f(x+\Delta x)-f(x)}{\Delta x}}}$$</li><li>单侧差分公式近似（$\Delta{x}$的值接近于0）：$\displaystyle{f^\prime(x)\approx\frac{f(x+\Delta x)}{\Delta x}}$</li><li>中心差分公式近似（$\Delta{x}$的值为接近于0的正数）：$\displaystyle{f^\prime(x)\approx\frac{f(x+\Delta x)-f(x-\Delta x)}{2\Delta x}}$</li><li>四则运算的求导公式：<br>$$<br>(f(x)\plusmn g(x))^\prime&#x3D;f^\prime(x)\plusmn g^\prime(x)\<br>(cf(x))^\prime&#x3D;cf^\prime(x)\<br>(f(x)g(x))^\prime&#x3D;f^\prime(x)g(x)+f(x)g^\prime(x)\<br>\left(\frac{f(x)}{g(x)}\right)^\prime&#x3D;\frac{f^\prime(x)g(x)-f(x)g^\prime(x)}{g^2(x)}\<br>(f(g(x)))^\prime&#x3D;f^\prime(g(x))g^\prime(x)<br>$$</li></ul><h3 id="1-2-2-机器学习中的常用函数"><a href="#1-2-2-机器学习中的常用函数" class="headerlink" title="1.2.2 机器学习中的常用函数"></a>1.2.2 机器学习中的常用函数</h3><ul><li>softplus函数：$f(x)&#x3D;\ln(1+e^x)$，是ReLu函数在$\max(0,x)$的光滑近似。</li><li>如果一个函数所有不可导点的集合为有限集或无限可数集，则称该函数<strong>几乎处处可导</strong>。</li></ul><h3 id="1-2-4-微分"><a href="#1-2-4-微分" class="headerlink" title="1.2.4 微分"></a>1.2.4 微分</h3><ul><li>函数在某一区间有定义，关于$x$的增量$\Delta{x}$，如果函数的增量$\Delta{y}&#x3D;f(x_0+\Delta{x})-f(x_0)$可以表示成$\Delta{y}&#x3D;A\Delta{x}+o(\Delta{x})$，其中$A$是不依赖于$\Delta{x}$的常数，$o(\Delta{x})$是$\Delta{x}$的高阶无穷小，则称函数在$x_0$处可微。</li><li>如果函数可微，则导数与微分的关系为：$dy&#x3D;f^\prime(x)dx$。微分用一次函数近似代替邻域内的函数值而忽略了更高次的项，几何意义是在点$(x_0,f(x_0))$处自变量增加$\Delta{x}$时切线函数$y&#x3D;f^\prime(x_0)(x-x_0)+f(x_0)$的增量$f^\prime(x_0)\Delta{x}$。</li></ul><h3 id="1-2-5-导数与函数的单调性"><a href="#1-2-5-导数与函数的单调性" class="headerlink" title="1.2.5 导数与函数的单调性"></a>1.2.5 导数与函数的单调性</h3><ul><li>由于导数是函数变化率的极限，因此如果在$x$点处它的值为正，则在该点处自变量增大时函数值也增大；如果为负，则自变量增大时函数值减小。<code>拉格朗日中值定理可证明</code></li><li>利用导数可以证明某些不等式，其思路是证明函数在某一区间内单调，因此在区间端点处取得极值。</li></ul><h3 id="1-2-6-极值判别法则"><a href="#1-2-6-极值判别法则" class="headerlink" title="1.2.6 极值判别法则"></a>1.2.6 极值判别法则</h3><ul><li>邻域内$\geq$、$\leq$为极值，去心邻域内$\gt$、$\lt$为严格极值。</li><li><strong>费马（Fermat）定理</strong>：假设函数在$x_0$处可导，如果在$x_0$取得极值，必定存在$f^\prime(x_0)&#x3D;0$。<code>可导函数取极值的一阶必要条件</code></li><li><strong>驻点（Stationary point）</strong>：导数等于0的点。</li><li>驻点处二阶导大于0为严格极小值，小于0为严格极大值。如果等于0，则假设$f^\prime(x_0)&#x3D;\cdots&#x3D;f^{(n-1)}(x_0)&#x3D;0,f^{n}(x_0)\neq0$，当$n$为偶数时，$f^{n}(x_0)\gt0$为严格极小值，$f^{n}(x_0)\lt0$为严格极大值；当$n$为奇数，该点不是极值点。<code>二阶充分条件——可用泰勒公式证明</code></li><li><strong>鞍点（Saddle point）</strong>：该点不是极值点，会导致数值优化算法如梯度下降法无法找到真正的极值点。</li></ul><h3 id="1-2-7-导数与函数的凹凸性"><a href="#1-2-7-导数与函数的凹凸性" class="headerlink" title="1.2.7 导数与函数的凹凸性"></a>1.2.7 导数与函数的凹凸性</h3><ul><li>Mix定义域的值域$\left{f(\theta{x}+(1-\theta)y)\right}$与值域的Mix$\left{\theta f(x)+(1-\theta)f(y)\right}$之间的关系，连线在上为凸函数（$\leq$），连线在下为凹函数（$\geq$）（欧美标准）。<code>去掉等号的为严格凹凸函数</code></li><li>凸函数二阶导大于0，凹函数二阶导小于0，二阶导是凹凸函数的充分必要条件。</li><li><strong>拐点</strong>：函数凹凸性的分界点，在拐点处二阶导为0，且两侧二阶导异号。</li><li>凸函数有优良的性质，可以保证优化算法找到函数的极小值点。</li></ul><h2 id="1-3-微分中值定理-Mean-Value-Theorem"><a href="#1-3-微分中值定理-Mean-Value-Theorem" class="headerlink" title="1.3 微分中值定理 Mean Value Theorem"></a>1.3 微分中值定理 Mean Value Theorem</h2><h3 id="1-3-1-罗尔（Rolle）中值定理"><a href="#1-3-1-罗尔（Rolle）中值定理" class="headerlink" title="1.3.1 罗尔（Rolle）中值定理"></a>1.3.1 罗尔（Rolle）中值定理</h3><ul><li>如果函数$f(x)$在闭区间$[a,b]$内连续，在开区间$(a,b)$内可导，且在区间的两个端点处的值相等$f(a)&#x3D;f(b)$，则在区间$[a,b]$内至少存在一个点$\xi$使得$f^\prime(\xi)&#x3D;0$。<code>可以使用费马定理证明</code></li><li>对于区间两端点处的函数值相等的函数，在区间内至少存在一点的导数值为0，该点处的切线与$x$轴平行。</li></ul><h3 id="1-3-2-拉格朗日（Lagrange）中值定理"><a href="#1-3-2-拉格朗日（Lagrange）中值定理" class="headerlink" title="1.3.2 拉格朗日（Lagrange）中值定理"></a>1.3.2 拉格朗日（Lagrange）中值定理</h3><ul><li>如果函数$f(x)$在闭区间$[a,b]$内连续，在开区间$(a,b)$内可导，则在区间$[a,b]$内至少存在一个点$\xi$使得$\displaystyle{f^\prime(\xi)&#x3D;\frac{f(b)-f(a)}{b-a}}$。<code>可以将函数剪掉一个线性函数构造出两个端点值相等的函数来证明</code></li><li>在区间$(a,b)$内至少存在一个点$\xi$，在$(\xi,f(\xi))$处的切线与两点之间的割线平行。</li></ul><h3 id="1-3-3-柯西（Cauchy）中值定理"><a href="#1-3-3-柯西（Cauchy）中值定理" class="headerlink" title="1.3.3 柯西（Cauchy）中值定理"></a>1.3.3 柯西（Cauchy）中值定理</h3><p>函数$f(x),g(x)$在$[a,b]$内连续，在$(a,b)$内可导，且$\forall{x\in(a,b)},g^\prime(x)\neq0$，则存在$\xi\in(a,b)$使得$\displaystyle{\frac{f^\prime(\xi)}{g^\prime(\xi)}&#x3D;\frac{f(b)-f(a)}{g(b)-g(a)}}$。<code>可直接用Lagrange中值定理变形得到</code></p><h3 id="1-4-泰勒公式"><a href="#1-4-泰勒公式" class="headerlink" title="1.4 泰勒公式"></a>1.4 泰勒公式</h3><p>如果一个函数<strong>足够光滑</strong>且在某点处<strong>各阶导数均存在</strong>，以该点处的各阶导数作为系数，构造出多项式来近似函数在该点邻域中任意点处的函数值，此多项式被称为<strong>泰勒多项式</strong>（Taylor polynomial）。<br>$$<br>f(x)&#x3D;f(a)+\frac{f^\prime(a)}{1!}(x-a)+\frac{f^{\prime\prime}(a)}{2!}(x-a)^2+\cdots+\frac{f^{(n)}(a)}{n!}(x-a)^n+R_n(x)<br>$$</p><ul><li>当$R_n(x)&#x3D;o((x-a)^n)$时，得到带皮亚诺余项的泰勒公式；</li><li>当$\displaystyle{R_n(x)&#x3D;\frac{f^{(n+1)}(\theta)}{(n+1)!}(x-a)^{(n+1)}},\theta\in(a,x)$时，得到带拉格朗日余项的泰勒公式；</li><li>函数在$x&#x3D;0$处的泰勒公式被称为麦克劳林（Maclaurin）公式。</li></ul><p>泰勒公式建立了可导函数与其各阶导数之间的联系，同时用多项式对函数进行逼近。</p><h2 id="1-5-不定积分"><a href="#1-5-不定积分" class="headerlink" title="1.5 不定积分"></a>1.5 不定积分</h2><h3 id="1-5-1-不定积分的定义与性质"><a href="#1-5-1-不定积分的定义与性质" class="headerlink" title="1.5.1 不定积分的定义与性质"></a>1.5.1 不定积分的定义与性质</h3><ul><li>不定积分是求导和微分的逆运算，记为$\int{f(x)dx}$，不定积分与原函数的关系为$\int{f(x)dx}&#x3D;F(x)+C$。如果函数$f(x)$的原函数存在，则称其可积。</li></ul><h3 id="1-5-2-换元积分法"><a href="#1-5-2-换元积分法" class="headerlink" title="1.5.2 换元积分法"></a>1.5.2 换元积分法</h3><p><code>基于复合函数求导公式推出</code></p><ul><li>凑微分法：$\int{f(u(x))u^\prime(x)dx}&#x3D;\int{f(u)du}&#x3D;F(u)$。</li><li>变量替换法：令$x&#x3D;u(t)$，则$\int{f(x)dx}&#x3D;\int{f(u(t))du(t)}$</li></ul><h3 id="1-5-3-分部积分法"><a href="#1-5-3-分部积分法" class="headerlink" title="1.5.3 分部积分法"></a>1.5.3 分部积分法</h3><p><code>基于乘法求导公式推出</code><br>$$\int{f(x)g^\prime(x)dx}&#x3D;f(x)g(x)-\int{f^\prime(x)g(x)dx}$$</p><blockquote><p>刘维尔定理指出，一个初等函数如果有初等的原函数，则它一定能写成同一个微分域的函数加上有限项该域上函数的对数的线性组合，否则不存在初等的原函数。</p></blockquote><h2 id="1-6-定积分"><a href="#1-6-定积分" class="headerlink" title="1.6 定积分"></a>1.6 定积分</h2><h3 id="1-6-1-定积分的定义与性质"><a href="#1-6-1-定积分的定义与性质" class="headerlink" title="1.6.1 定积分的定义与性质"></a>1.6.1 定积分的定义与性质</h3><p>定积分将函数映射成实数，是和式的极限：$\displaystyle{\lim_{\Delta{x}\rightarrow0}\sum_{i&#x3D;1}^{n}{f(\xi_i)\Delta{x_i}}}$，$n$表示将区间$[a,b]$分成$N$份，定积分被记为$\int_{b}^{a}f(x)dx$。</p><ul><li>定积分具有线性性、区间可加性，将积分上下限颠倒，积分值相反。</li></ul><h3 id="1-6-2-牛顿-莱布尼茨公式-（Newton-Leibniz）"><a href="#1-6-2-牛顿-莱布尼茨公式-（Newton-Leibniz）" class="headerlink" title="1.6.2 牛顿-莱布尼茨公式 （Newton-Leibniz）"></a>1.6.2 牛顿-莱布尼茨公式 （Newton-Leibniz）</h3><p>微积分基本定理，建立了定积分与原函数的关系。如果函数在区间$[a,b]$内可积，则在此区间内定积分的值等于其原函数在区间两个端点处函数值之差<code>可用Lagrange中值定理证明</code>：<br>$$\int_{b}^{a}f(x)dx&#x3D;F(x)|_a^b$$</p><h3 id="1-6-4-变上限积分"><a href="#1-6-4-变上限积分" class="headerlink" title="1.6.4 变上限积分"></a>1.6.4 变上限积分</h3><p>积分上限为自变量$x$，变上限积分函数是被积分函数的一个原函数，概率论中连续随机变量的分布函数是典型的变上限积分函数。</p><h3 id="1-6-6-广义积分"><a href="#1-6-6-广义积分" class="headerlink" title="1.6.6 广义积分"></a>1.6.6 广义积分</h3><p>用于积分区间为无限或是积分区间有限但被积分函数无界的情况，又称反常积分。前者为无穷限广义积分，后者为瑕积分。</p><h2 id="1-7-常微分方程"><a href="#1-7-常微分方程" class="headerlink" title="1.7 常微分方程"></a>1.7 常微分方程</h2><h3 id="1-7-1-基本概念"><a href="#1-7-1-基本概念" class="headerlink" title="1.7.1 基本概念"></a>1.7.1 基本概念</h3><p><code>微分方程（Differential Equation，DE）是含有自变量、函数与其导数的方程，方程的解是函数。</code><br>含有自变量、函数以及函数各阶导数的方程称为常微分方程（Ordinary DE，ODE），它的解为一元函数。<br>$$f(x,y^{(n)},\cdots,y^\prime,y)&#x3D;0$$</p><ul><li>如果微分方程式未知函数以及各阶导数的一次方程，则称为线性微分方程，否则非线性微分方程。</li><li>如果线性微分方程中未知函数项以及各阶导数项的系数都是常数，则称为常系数线性微分方程。</li><li>并非所有微分方程的解都存在。对于初值问题，<strong>Cauchy-Lipschitz定理</strong>给出了解的存在性和唯一性的判别条件。即使解存在，也只有少数简单的微分方程可以求得解析解。在无法求得解析解时，可以利用数值计算的方法近似求解，常用的有<strong>Runge-Kutta法和Richardson外推法</strong>。</li></ul><h3 id="1-7-2-一阶线性微分方程"><a href="#1-7-2-一阶线性微分方程" class="headerlink" title="1.7.2 一阶线性微分方程"></a>1.7.2 一阶线性微分方程</h3><ul><li>齐次方程：$y^\prime+ay&#x3D;0$</li><li>非齐次方程：$y^\prime+ay&#x3D;b(x)$<blockquote><p>利用指数函数的特性，方程两边同乘以$e^{ax}$</p></blockquote></li></ul><h2 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h2><h3 id="Appx-I-常用极限"><a href="#Appx-I-常用极限" class="headerlink" title="Appx-I 常用极限"></a>Appx-I 常用极限</h3><blockquote><ol><li>$\displaystyle{\lim_{n\rightarrow+\infty}(1+\frac{1}{n})^n&#x3D;e}$</li><li>当$x\rightarrow0$时，典型的等价无穷小：$sin(x)\sim{x},arcsin(x)\sim{x},tan(x)\sim{x},ln(1+x)\sim{x},e^x-1\sim{x},1-cos(x)\sim{\frac{x^2}{2}},\sqrt[n]{1+x}-1\sim{\frac{x}{n}},a^x-1\sim{x\ln(a)}$</li></ol></blockquote><h3 id="Appx-II-基本函数的求导公式"><a href="#Appx-II-基本函数的求导公式" class="headerlink" title="Appx-II 基本函数的求导公式"></a>Appx-II 基本函数的求导公式</h3><table><thead><tr><th align="center">基本函数</th><th>求导公式</th></tr></thead><tbody><tr><td align="center">幂函数</td><td>$(x^a)^\prime&#x3D;ax^{a-1}$</td></tr><tr><td align="center">指数函数</td><td>$(a^x)^\prime&#x3D;a^x\ln{a}$</td></tr><tr><td align="center">对数函数</td><td>$(\log_ax)^\prime&#x3D;\frac{1}{\ln{a}}\frac{1}{x}$</td></tr><tr><td align="center">三角函数</td><td>$(sin(x))^\prime&#x3D;cos(x)$</td></tr><tr><td align="center">三角函数</td><td>$(cos(x))^\prime&#x3D;-sin(x)$</td></tr><tr><td align="center">三角函数</td><td>$(tan(x))^\prime&#x3D;sec^2(x)$</td></tr><tr><td align="center">三角函数</td><td>$(cot(x))^\prime&#x3D;-csc^2(x)$</td></tr><tr><td align="center">反三角函数</td><td>$(arcsin(x))^\prime&#x3D;\frac{1}{\sqrt{1-x^2}}$</td></tr><tr><td align="center">反三角函数</td><td>$(arccos(x))^\prime&#x3D;-\frac{1}{\sqrt{1-x^2}}$</td></tr><tr><td align="center">反三角函数</td><td>$(arctan(x))^\prime&#x3D;\frac{1}{1+x^2}$</td></tr></tbody></table><h3 id="Appx-III-基本函数的麦克劳林公式"><a href="#Appx-III-基本函数的麦克劳林公式" class="headerlink" title="Appx-III 基本函数的麦克劳林公式"></a>Appx-III 基本函数的麦克劳林公式</h3><table><thead><tr><th align="center">函数</th><th>麦克劳林公式</th></tr></thead><tbody><tr><td align="center">$\frac{1}{1-x}$</td><td>$1+x+x^2+\cdots+x^n+o(x^n)$</td></tr><tr><td align="center">$e^x$</td><td>$1+x+\frac{x^2}{2!}+\cdots+\frac{x^n}{n!}+o(x^n)$</td></tr><tr><td align="center">$\sin x$</td><td>$x-\frac{x^3}{3!}+\frac{x^5}{5!}-\cdots+\frac{(-1)^{n-1}x^{2n-1}}{(2n-1)!}+o(x^{2n-1})$</td></tr><tr><td align="center">$\cos x$</td><td>$1-\frac{x^2}{2!}+\frac{x^4}{4!}-\cdots+\frac{(-1)^nx^{2n}}{(2n)!}+o(x^{2n})$</td></tr><tr><td align="center">$\ln(1+x)$</td><td>$x-\frac{x^2}{2}+\frac{x^3}{3}-\cdots+\frac{(-1)^{n+1}x^n}{n}+o(x^n)$</td></tr></tbody></table><h3 id="Appx-IV-基本函数的积分公式"><a href="#Appx-IV-基本函数的积分公式" class="headerlink" title="Appx-IV 基本函数的积分公式"></a>Appx-IV 基本函数的积分公式</h3><table><thead><tr><th align="center">函数</th><th>积分公式</th></tr></thead><tbody><tr><td align="center">常数函数</td><td>$\int{a}dx&#x3D;ax+C$</td></tr><tr><td align="center">幂函数</td><td>$\int{x^a}dx&#x3D;\frac{1}{a+1}x^{a+1}+C,a\neq-1$</td></tr><tr><td align="center">幂函数</td><td>$\int{\frac{1}{x}}dx&#x3D;\ln$&amp;#124;$x$&amp;#124;$+C$</td></tr><tr><td align="center">指数函数</td><td>$\int{e^x}dx&#x3D;e^x+C$</td></tr><tr><td align="center">指数函数</td><td>$\int{a^x}dx&#x3D;\frac{1}{\ln{a}}a^x+C,a&gt;0,a\neq1$</td></tr><tr><td align="center">三角函数</td><td>$\int{sin(x)}dx&#x3D;-cos(x)+C$</td></tr><tr><td align="center">三角函数</td><td>$\int{cos(x)}dx&#x3D;sin(x)+C$</td></tr><tr><td align="center">三角函数</td><td>$\int{tan(x)}dx&#x3D;-\ln$&amp;#124;$cos(x)$&amp;#124;$+C$</td></tr><tr><td align="center">三角函数</td><td>$\int{cot(x)}dx&#x3D;\ln$&amp;#124;$sin(x)$&amp;#124;$+C$</td></tr><tr><td align="center">三角函数</td><td>$\int{\frac{1}{cos^2(x)}}dx&#x3D;tan(x)+C$</td></tr><tr><td align="center">三角函数</td><td>$\int{\frac{1}{sin^2(x)}}dx&#x3D;-cot(x)+C$</td></tr><tr><td align="center">反三角函数</td><td>$\int{\frac{1}{\sqrt{1-x^2}}}dx&#x3D;arcsin(x)+C$</td></tr><tr><td align="center">反三角函数</td><td>$\int{\frac{1}{\sqrt{1-x^2}}}dx&#x3D;-arccos(x)+C$</td></tr><tr><td align="center">反三角函数</td><td>$\int{\frac{1}{1+x^2}}dx&#x3D;arctan(x)+C$</td></tr></tbody></table>]]></content>
      
      
      <categories>
          
          <category> 《机器学习的数学》-雷明 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 学习笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Git使用教程</title>
      <link href="/2022/05/15/Git-skils/"/>
      <url>/2022/05/15/Git-skils/</url>
      
        <content type="html"><![CDATA[<h1 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h1><blockquote><p>在本地安装好Git</p></blockquote><h1 id="Git常用命令"><a href="#Git常用命令" class="headerlink" title="Git常用命令"></a>Git常用命令</h1><span id="more"></span><pre><code class="bash">git init            # 初始化git add .            # 上传所有文件到缓存区git status -s        # 查看缓存区文件状态git rm -r --cache &lt;文件名&gt;    # 清除缓冲区文件git commit -m &#39;&#39;    # 上传日志git branch -M main            # 转换branch</code></pre><h1 id="Git远程连接GitHub"><a href="#Git远程连接GitHub" class="headerlink" title="Git远程连接GitHub"></a>Git远程连接GitHub</h1><h2 id="ssh-keygen常用命令"><a href="#ssh-keygen常用命令" class="headerlink" title="ssh-keygen常用命令"></a>ssh-keygen常用命令</h2><pre><code class="bash">ssh-keygen -t rsa -C &#39;注释&#39; -f &#39;~/.ssh/自定义文件名&#39;# 命令选项-b：指定密钥长度-e：读取openssh的私钥或者公钥文件-C：添加注释-f：指定用来保存密钥的文件名-i：读取未加密的ssh-v2兼容的私钥/公钥文件，然后在标准输出设备上显示openssh兼容的私钥/公钥-l：显示公钥文件的指纹数据-N：提供一个新密语-P：提供（旧）密语-q：静默模式-t：指定要创建的密钥类型</code></pre><blockquote><p><code>ssh-keygen</code>用于在<code>.ssh</code>文件夹下生成私钥文件<code>id_rsa</code>和公钥文件<code>id_rsa.pub</code><br>GitHub似乎不能识别自定义的文件名，所以为GitHub生成密钥时请使用默认文件名，即不指定-f</p></blockquote><h2 id="在GitHub中配置SSH"><a href="#在GitHub中配置SSH" class="headerlink" title="在GitHub中配置SSH"></a>在GitHub中配置SSH</h2><ol><li>登录GitHub，进入<code>Setting</code></li><li>找到<code>SSH and GPG keys</code>，点击<code>New SSH key</code>，自定义title</li><li>将<code>id_rsa.pub</code>的内容复制到<code>key</code>内<br><img src="/../images/Snipaste_2022-05-15_17-43-21.png" alt="Github设置SSH界面"></li></ol><h2 id="远程连接命令"><a href="#远程连接命令" class="headerlink" title="远程连接命令"></a>远程连接命令</h2><pre><code class="bash">ssh -T git@github.com # 测试是否连接到GitHubgit remote add origin git@github.com:&lt;用户名&gt;/&lt;仓库名&gt;.git  # 链接git remote -v        # 查看已建立的链接git remote rm XX    # 删除链接XXgit push -u origin master    # 上传到GitHub</code></pre><h1 id="Git修改commit注释"><a href="#Git修改commit注释" class="headerlink" title="Git修改commit注释"></a>Git修改commit注释</h1><h2 id="修改最后一次提交的commit注释"><a href="#修改最后一次提交的commit注释" class="headerlink" title="修改最后一次提交的commit注释"></a>修改最后一次提交的commit注释</h2><pre><code class="bash">git commit --amend  # 打开nano/vim编辑commitgit log             # 修改完保存退出，然后打印log查看是否修改成功# nano编辑器：如同记事本一样直接删除插入，C^表示Ctrl+，M^表示Alt+# vim编辑器： i-insert模式，:wq-保存退出</code></pre><h2 id="修改任意一次commit注释"><a href="#修改任意一次commit注释" class="headerlink" title="修改任意一次commit注释"></a>修改任意一次commit注释</h2><p><strong>查看提交日志，确认要修改的提交历史</strong></p><pre><code class="bash">git log</code></pre><p><strong>变基操作</strong></p><pre><code class="bash">git rebase -i &lt;commit range&gt;# 示例git rebase -i HEAD~2    # 表示当前提交到2次以前的提交git rebase -i &lt;hash值&gt;  # 表示hash值对应的某次提交</code></pre><p><strong>编辑commit</strong></p><blockquote><ol><li>将pick修改为edit</li><li>将原始注释改为新的注释</li><li>保存退出</li></ol></blockquote><p><strong>执行commit修改</strong></p><pre><code class="bash">git commit --amendgit rebase --continue</code></pre><h2 id="修改已经Push到远程的commit注释"><a href="#修改已经Push到远程的commit注释" class="headerlink" title="修改已经Push到远程的commit注释"></a>修改已经Push到远程的commit注释</h2><p>首先把最新版本从远程pull到本地，然后使用上面👆的方法修改，在强制push到远程。</p><pre><code class="bash">git push --force origin master</code></pre><h2 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h2><p>高频命令</p><pre><code class="bash">git log --oneline  # 精简在一行显示一条history记录git log --graph    # 可视化提交的历史git branch [new branch name] [commit id]   # 从历史提交处创建分支</code></pre>]]></content>
      
      
      <categories>
          
          <category> Using Skills </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Git </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>VScode配置Python远程调试</title>
      <link href="/2022/05/03/VScode-Python-Remote/"/>
      <url>/2022/05/03/VScode-Python-Remote/</url>
      
        <content type="html"><![CDATA[<h1 id="必要插件安装"><a href="#必要插件安装" class="headerlink" title="必要插件安装"></a>必要插件安装</h1><blockquote><ol><li>安装Remote-SSH （或者Remote Development这个插件合集，其中包含了SSH）</li><li>安装Python Extensions</li></ol></blockquote><span id="more"></span><h1 id="远程服务器配置"><a href="#远程服务器配置" class="headerlink" title="远程服务器配置"></a>远程服务器配置</h1><p>点击<code>Remote Explorer</code>，在下拉框中选择<code>SSH Targets</code>，点击⚙️配置<code>C:\Users\Administrator\.ssh\config</code></p><pre><code class="php"># Read more about SSH config files: https://linux.die.net/man/5/ssh_configHost Deep-H    HostName 192.168.1.XX   # 服务器IP    User XXXXX              # 用户名</code></pre><p>如果报错，尝试在VScode设置中搜索<code>Show Login Terminal</code>，勾选下方<code>Always reveal the SSH login terminal</code>。<br><img src="/../images/Snipaste_2022-05-03_18-01-50.png" alt="远程服务器配置"><br>配置完成后，在需要连接的条目上右键，选择<code>Connect to Host in New Window</code>或者<code>Connect to Host in Current Window</code></p><h1 id="配置服务器免密登录"><a href="#配置服务器免密登录" class="headerlink" title="配置服务器免密登录"></a>配置服务器免密登录</h1><h2 id="在本地生成公-私钥对"><a href="#在本地生成公-私钥对" class="headerlink" title="在本地生成公-私钥对"></a>在本地生成公-私钥对</h2><pre><code class="bash">ssh-keygen -t rsa -b 4096 -C &quot;your_email@example.com&quot; -f ~/.ssh/文件名# -t type 指定要创建的密钥类型。可以使用：“rsa1”(SSH-1) “rsa”(SSH-2) “dsa”(SSH-2)# -b bits 指定密钥长度。对于RSA密钥，最小要求768位，默认是2048位。DSA密钥必须恰好是1024位(FIPS 186-2 标准的要求)。# -C comment 提供一个新注释# -f ~/.ssh/文件名 公钥和私钥的输出位置和对应的文件名# 最简单常用的用法：ssh-keygen -t rsa -C &quot;your_email@example.com&quot;</code></pre><p>命令运行之后，会在<code>.ssh</code>文件夹下生成<code>id_rsa.pub</code>和<code>id_rsa</code></p><h2 id="在远程端添加公钥"><a href="#在远程端添加公钥" class="headerlink" title="在远程端添加公钥"></a>在远程端添加公钥</h2><p>进入<code>~/.ssh</code>将<code>id_rsa.pub</code>的内容追加到<code>authorized_keys</code>中</p><pre><code class="bash"># 如果没有.ssh文件夹则创建mkdir ~/.ssh# 如果没有authorized_keys文件则创建touch ~/.ssh/authorized_keys# 确认.ssh和authorized_keys的权限，必要时修改权限chmod 700 ~/.sshchmod 600 ~/.ssh/authorized_keys# 追加id_rsa.pub内容，此命令需确保.pub文件与authorized_keys在同一目录下cat id_rsa.pub &gt;&gt; authorized_keys</code></pre><h2 id="修改Remote-SSH配置"><a href="#修改Remote-SSH配置" class="headerlink" title="修改Remote-SSH配置"></a>修改Remote-SSH配置</h2><pre><code class="php"># Read more about SSH config files: https://linux.die.net/man/5/ssh_configHost Deep-H    HostName 192.168.1.XX   # 服务器IP    User XXXXX              # 用户名    IdentityFile XXXX\.ssh\id_rsa     # 本地生成的私钥文件</code></pre><h1 id="Python代码调试"><a href="#Python代码调试" class="headerlink" title="Python代码调试"></a>Python代码调试</h1><h2 id="配置Python环境"><a href="#配置Python环境" class="headerlink" title="配置Python环境"></a>配置Python环境</h2><p><code>Run</code>-&gt;<code>Add Configuration...</code>-&gt;<code>Python File</code>打开<code>launch.json</code>文件，在该文件中配置：</p><pre><code class="json">&#123;    // Use IntelliSense to learn about possible attributes.    // Hover to view descriptions of existing attributes.    // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387    &quot;version&quot;: &quot;0.2.0&quot;,    &quot;configurations&quot;: [        &#123;            &quot;name&quot;: &quot;Python: Current File&quot;,            &quot;type&quot;: &quot;python&quot;,            &quot;request&quot;: &quot;launch&quot;,            &quot;program&quot;: &quot;$&#123;file&#125;&quot;,            &quot;console&quot;: &quot;integratedTerminal&quot;,            &quot;justMyCode&quot;: true,            &quot;cwd&quot;: &quot;$&#123;fileDirname&#125;&quot;  // 设置相对路径，在debug时可以切换到当前文件所在目录        &#125;,    ]&#125;</code></pre><blockquote><p><code>F1</code>-&gt;<code>Python: Select Interpreter</code>选择Python解释器</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> VScode使用教程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> VScode.config </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>凯文·凯利的103条人生建议</title>
      <link href="/2022/05/01/PostReading-KK-lifestream/"/>
      <url>/2022/05/01/PostReading-KK-lifestream/</url>
      
        <content type="html"><![CDATA[<p><strong>硅谷精神之父在70岁生日之际送给大家的一份礼物🎁</strong></p><ul><li>大约 99% 的情况下，正确开始的时间就是现在。<span id="more"></span></li><li>别人不会像你一样对你的财产印象深刻。（Morgan Housel《金钱心理学》里面的一句话，可粗浅理解为禀赋效应）</li><li>永远不要为你不想成为的人工作。</li><li>培养 12 个爱你的人，他们比 1200 万个喜欢你的人更有价值。</li><li>不要一直犯同样的错误，做新的试错。</li><li>如果你驻足欣赏音乐家或街头艺人表演超过一分钟，你就欠他们一美元。</li><li>在「但是」一词之前说的任何话都不算数</li><li>原谅别人时，对方可能不会注意，但你自己会被治愈。宽恕不为他人，是给自己的礼物。</li><li>礼貌无价。用完马桶后把盖子放下，等电梯时先出后进，把购物车放回指定区域。借东西归还时要比你得到时的状态更好（装满，清洁）。</li><li>两方发生争执时，找第三方。</li><li>效率被高估了，偷懒被严重低估了。定期安排的休息日、假期、轮休、漫无目的的散步和休息时间对于任何类型的最佳表现都是必不可少的。最好的职业道德包括良好的休息道德。</li><li>当你领导群体时，真正的工作是创造更多领导者，而不是更多的追随者。</li><li>私下批评，公开表扬。</li><li>人生的每一门课程会随时间依次呈现给你。掌握所需的一切能力取决于你的内心。真正吸取一次教训，你就会面临下一个挑战。如果你生存了下来，那意味着你还将得到教训。</li><li>从老师那里得到一切知识是学生的责任，而老师也有责任从学生身上学到一切。</li><li>如果在一场比赛中获胜变得过于重要，那就改变规则并让它变得更有趣。改变规则本身也可以是新的比赛。</li><li>求人赞助，他们会给你建议；向别人寻求建议，他们会给你钱。</li><li>生产力通常会有误区。不要以更快完成任务为导向，而要以更好完成任务为目标，寻找你想一直做下去的事。</li><li>即时向供应商、工人、承包商支付你所欠的款项。他们下次才会不遗余力地优先与你合作。</li><li>我们对自己说的最大的谎是「不需要写下来，我能记住」。</li><li>作为意识体，成长是由你愿意进行的不舒服谈话的数量来衡量的。</li><li>说话要自信，就好像你是对的，但同时要仔细听，就好像你是错的。</li><li>简单的测量：伸平手臂与肩同高，两个指尖的距离就是你的身高。</li><li>努力（锻炼、陪伴、工作）的一致性比数量更重要。没有什么比每天做的小事更重要了，这比你偶尔做的事情更重要。</li><li>做艺术不是自私的；它是为他人服务的。如果你不做你的事，你就是在欺骗我们。</li><li>永远不要问一个女人是否怀孕。她愿意的话会主动告诉你。</li><li>你需要三种品质：不放弃某件事情直到最终成功，放弃做无用功，以及信任其他人来帮助你区分这两种情况的能力。</li><li>公开演讲时，要经常停顿。在你以新的方式说某件事情之前暂停，在你说了你认为重要的事情之后暂停，并将暂停作为一种解脱，让听众吸收细节。</li><li>没有所谓的「准时」之说，你要么迟到，要么提前。你需要做出选择。</li><li>问问那些你钦佩的人：他们的运气时常出现在远离主要目标的弯道上。所以接受走弯路。对任何人来说，生活都不是一条直线。</li><li>在互联网上获得正确答案的最好方法是发布一个明显错误的答案，并等待有人来纠正你。（以维基百科作者坎宁安命名的定律，维基百科可能是本定律的最佳例子。）</li><li>通过奖励好的行为而不是惩罚坏的行为，你会得到 10 倍的效果，特别是在儿童和动物身上。</li><li>花尽可能多的时间精心设计电子邮件的主题行，因为它往往是人们阅读的唯一内容。</li><li>生活不是等待暴风雨过去，而是要学会在雨中起舞。</li><li>查看求职者推荐信时要意识到，雇主可能不愿意或被禁止说任何负面的东西，所以留下或发送一条信息说：「如果你强烈推荐这个求职者，他是超级棒的，请给我回信。」如果他们不回复，就当作是一种否定。</li><li>使用密码管理器：它们更安全、更简单、更强大。</li><li>接受教育学到的一半技能，是让你学会可以忽略一些东西。</li><li>设立大目标的优势在于，制定非常高的标准，即使失败，也可能是普通人眼里的成功。</li><li>了解自己的一个好方法是认真地反思别人身上让你反感的一切。</li><li>在酒店房间里要把你所有的东西都放在显眼的位置，集中到一个地方，不要放在抽屉里。这样你就不会落下任何东西。如果你需要把充电器之类的东西放在一边，就在它旁边放几件其他的大件物品，拉下三件物品的可能性比只拉下一件小。</li><li>拒绝或回避赞美是不礼貌的。即使你认为它不值得，也要感谢地接受它。</li><li>始终记得阅读纪念碑旁边的牌匾。</li><li>当你有一点成绩的时候，自己是冒牌者的感觉可能是真的。我在愚弄谁呢？但当你创造出只有你—以独特才能和经验—才能做到的事情时，那么你绝对不是冒牌货。这是天命所归。在只有你能做的事情上努力是你的职责。</li><li>在逆境中的表现，比你在顺境里所做的更重要。</li><li>做对他人有益的事。</li><li>当你打开油漆，哪怕只用一丁点，无论你多么小心，它总会沾到你的衣服。准备好着装。</li><li>为了让小孩子们在汽车旅行中表现良好，准备一袋他们最喜欢的糖果，每当他们不听话时，就向窗外扔一块。</li><li>你无法让聪明人仅仅为了钱而奋力工作。</li><li>当你不知道该为某项任务付给某人多少钱时，问他「怎样才算公平？」，他们的回答通常就是该有的价格。</li><li>90% 的东西都没有意义。如果你认为自己不喜欢歌剧、爱情小说、TikTok、乡村音乐、素食、NFT，保持尝试，看看是否能找到有意义的 10%。</li><li>人们会根据你对那些和你无利益冲突的人的态度好坏来评价你。</li><li>我们倾向于高估自己一天内能做的事，又低估自己在十年内能取得的成就。十年时间足以完成奇迹般的大事。一场漫长的比赛包含众多小目标，积累之后形成量变。</li><li>感谢那位改变了你一生的老师。</li><li>你不可能用别人无法理解的逻辑给别人讲道理。</li><li>最好的工作可能是你不能胜任的工作，因为它会最大限度利用你的能力。所以请申请你不能胜任的工作。</li><li>买旧书。他们有和新书一样的字。也可以去图书馆。</li><li>你可以做任何你想做的事，所以做一个提前结束会议的人。</li><li>智者说：在你说话之前，让你的话通过三道门。在第一个大门问自己「这是真的吗？」 在第二道门前问「有必要吗？」在第三道门前问「是好的吗？」</li><li>走楼梯。</li><li>你为某样东西实际支付的费用至少是其标价的两倍，因为你需要花费时间精力和钱来设置、学习、维护、修理，以及最终的处置。不是所有的价格都体现在标签上。实际成本是标价的 2 倍。</li><li>当你到达酒店的房间时，确认紧急出口。这只需要一分钟时间。</li><li>回答「我现在应该做什么？」的唯一有效方式是首先解决「我应该成为谁？」的问题。</li><li>在高于平均水平的时间内持续的平均水平回报会产生非凡的效果。请买长线。</li><li>对无礼的陌生人保持极致风度是很令人感动的。</li><li>一个不太聪明但容易沟通的人，可能比一个超级聪明但难以沟通的人做得更好。这是件好事，因为提高你的沟通能力比提高你的智力要容易得多。</li><li>偶尔受骗是相信每个人的优点的小代价，因为当你相信别人的优点时，他们通常也会给你最好的回报。</li><li>艺术的表现形式是无穷无尽的。</li><li>要想在孩子身上取得最好的效果，只花你认为应该花的一半的钱，但花双倍的时间陪他们在一起。</li><li>购买最新的本地旅游指南。每年扮演一次游客，你会学到很多东西。</li><li>不要排队等候吃著名的东西，一般都不值得。</li><li>想要迅速弄清新认识的一个人的真实性格，让他们连接到一个慢得不能再慢的网络上。观察一下。</li><li>世俗化成功的处方：做一些奇怪的事情。让你的怪异成为一种习惯。</li><li>备份你的备份。至少要有一个物理备份和一个云端的备份，两者最好都有多于一个备份。如果你丢失了你的所有数据、照片、笔记，你会花多少钱来找回它们？与遗憾相比，备份很便宜。</li><li>不要相信你认为自己相信的一切。</li><li>想要发出紧急信号，使用三法则；3 声喊叫、3 声喇叭声或 3 声口哨声。</li><li>在餐厅，您会点一些你知道好吃的东西，还是尝试一些新的东西？探索新事物与利用新事物的最佳平衡是：1:3。将 1&#x2F;3 的时间用于探索，将 2&#x2F;3 的时间用于深化。随着年龄的增长，更难花时间去探索，因为它似乎没有成效，目标就成了剩下的 1&#x2F;3。</li><li>真正的好机会不容易找到，更不会明码标注出来。</li><li>与某人初次见面并作介绍时，要与对方有眼神接触并默数到 4，这样你们都会记住对方。</li><li>如果你发现自己在想 「我的好刀（或者我的好笔）在哪里」，这意味着你有其他坏的东西，把它们扔掉。</li><li>当你陷入困境时，尝试向别人解释你的问题。通常当你提出问题的时候就能找到一个解决方案。解释问题是解决困境的一种方法。</li><li>在购买花园水管、延长线或梯子时，要买一个比你认为需要的长得多的，那才是正确的尺寸。</li><li>不必费心地与旧事物抗争，只需要创造新事物。</li><li>只需要给别人以赞赏，他们就能取得超出能力范围的伟大成就。</li><li>说起一段历史，巅峰之年总是第十几年，就像每个人十多岁的时候，那是每个人最好的年华。</li><li>从让一个人生气的事情大小就能看出一个人的价值。（这是丘吉尔的名言）</li><li>当你面向听众表达自己的观点时，最好将目光集中在几个人身上，而不是扫向整个房间，你的眼神代表你是否相信自己所说的话。</li><li>习惯远比一时兴起可靠得多，你需要养成习惯才能获得进步。就像健身锻炼，不要专注于塑形，而是要成为从不错过锻炼的人。</li><li>谈判时，不要以争取更大的蛋糕为目标，要以创造一个更大的蛋糕为目标。</li><li>如果你把今天所做的事情重复 365 次，明年你会成为你想成为的人吗？</li><li>你只能看到一个人的 2%，同样他们也只能看到你的 2%，你需要隐藏自己的 98%。</li><li>你的时间和空间是有限的，移除、舍弃、扔掉那些已无法让你快乐的事物，以便为新的快乐腾出空间。</li><li>我们的后代将取得令我们震惊的突破，如果我们有足够的想象力，可以设想一下他们利用目前已有的条件能够创造出什么，可以大胆猜测一下。</li><li>如果你想获得丰厚的回报，那么即使是不感兴趣的事，你也要充满好奇。</li><li>专注于方向而不是目的地。没有人能知道自己的命运，但坚持朝着正确的方向努力，你就会到达想去的地方。</li><li>每一个突破最开始都是荒谬可笑的，事实上如果它最开始不荒谬，那它就算不上突破。</li><li>如果你借给别人 20 美元，而他为了不还钱选择不再见你，那你们的关系只值 20 美元。</li><li>复制他人的成功是一个好的开始，复制自己是一个令人失望的结束。</li><li>为一份新工作谈判薪资的最佳时机是对方想要你之后，而不是之前。然后，双方都说出一个数字就成了一场博弈，但在你工作之前让雇佣者给出一个薪资水平对你来说是有益的。</li><li>与其躲避生活中的意外，不如直接面对这些风险。</li><li>如果你使用信用卡租车，不要购买额外的保险。</li><li>如果你对一个问题的观点能够从你对另一个问题的观点中预测出来，那么你可能正处于某种意识形态的掌控之中。实际上当你真正独立地思考一个问题，你的结论很难被预测。</li><li>争取在离世之前花光自己所有的钱。相比于给你的受益人，自己全部花光更有趣也更有意义。你填的最后一张支票应该是给殡仪馆，还应该拒付。</li><li>防止变老的主要方法是对新鲜事物保持好奇和惊讶。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 读后感 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Git在VScode中的配置</title>
      <link href="/2022/05/01/VScode-Git/"/>
      <url>/2022/05/01/VScode-Git/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本地安装Git，且已在环境变量中配置<br>Windows系统下的使用教程</p></blockquote><h1 id="在VScode中配置Git路径"><a href="#在VScode中配置Git路径" class="headerlink" title="在VScode中配置Git路径"></a>在VScode中配置Git路径</h1><p>在<code>settings.json</code>中添加配置</p><span id="more"></span><pre><code class="json">&quot;git.path&quot;: &quot;%Git安装目录%/Git/cmd/git.exe&quot;,</code></pre><h1 id="在VScode终端中添加Git-Bash"><a href="#在VScode终端中添加Git-Bash" class="headerlink" title="在VScode终端中添加Git Bash"></a>在VScode终端中添加Git Bash</h1><p>由于原有的Git Bash已经弃用，直接在<code>settings.json</code>中间中添加Git Bash路径是无法正确添加的，将得到如下错误信息：</p><blockquote><p>Value is not accepted. Valid values: “PowerShell”, “Windows PowerShell”, “Command Prompt”, “JavaScript Debug Terminal”.</p></blockquote><p>正确的做法是使用用新的规则配置：</p><pre><code class="json">&quot;terminal.integrated.profiles.windows&quot;: &#123;        &quot;Git-Bash&quot;: &#123;            // &quot;source&quot;: &quot;Git Bash&quot;, // 不可使用Git Bash            &quot;icon&quot;: &quot;logo-github&quot;,   // 设置图标，可选            &quot;path&quot;: [                &quot;%Git安装目录%/Git/bin/bash.exe&quot;            ],            &quot;args&quot;: []        &#125;,    &#125;,    &quot;terminal.integrated.defaultProfile.windows&quot;: &quot;Git-Bash&quot;, // 设置为默认，可选</code></pre><h1 id="文件改动无法显示Git的修改颜色标记"><a href="#文件改动无法显示Git的修改颜色标记" class="headerlink" title="文件改动无法显示Git的修改颜色标记"></a>文件改动无法显示Git的修改颜色标记</h1><p>这是由于VScode无法识别软连接文件路径造成的，只需在真实路径下打开文件就可以正常显示了。</p><h1 id="好用的插件"><a href="#好用的插件" class="headerlink" title="好用的插件"></a>好用的插件</h1><p><code>GitLens</code>: 强大的历史查看功能</p><h2 id="与历史版本对比修改差异"><a href="#与历史版本对比修改差异" class="headerlink" title="与历史版本对比修改差异"></a>与历史版本对比修改差异</h2><blockquote><p>使用<code>git reset</code>回退版本会将原本在回退版本之后的提交全部删除，如果仅是为了查看与某一次历史版本的修改差异可以使用如下方法：</p></blockquote><p><img src="/../images/Snipaste_2022-06-23_16-31-26.png" alt="查看单个文件的历史版本"><br>选择<code>Open Changes with Working File</code>查看当前工作目录下文件与某个历史文件之间的差异。</p>]]></content>
      
      
      <categories>
          
          <category> VScode使用教程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> VScode.config </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>解决LaTeX不显示参考文献问题</title>
      <link href="/2022/04/30/VScode-LaTex-no-bib/"/>
      <url>/2022/04/30/VScode-LaTex-no-bib/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本人使用的LaTeX环境为：<br>VScode 1.66.2<br>LaTeX-workshop v8.25.0<br>MikTex </p></blockquote><p>由于直接复制网络上他人的教程导致无法适用于自己的环境，bib的reference始终无法正确识别 [在正文中以？出现]，经过不断的尝试，终于找到原因：</p><span id="more"></span><p><strong>编译链设置不对</strong><br>网上的普遍配置是大多如下：</p><pre><code class="json">// 用于配置编译链&quot;latex-workshop.latex.recipes&quot;: [    &#123;        &quot;name&quot;: &quot;xelatex&quot;,        &quot;tools&quot;: [            &quot;xelatex&quot;        ]    &#125;,    &#123;        &quot;name&quot;: &quot;latexmk&quot;,        &quot;tools&quot;: [            &quot;latexmk&quot;        ]    &#125;,    &#123;        &quot;name&quot;: &quot;pdflatex-&gt;bibtex-&gt;pdflatex*2&quot;,        &quot;tools&quot;: [            &quot;pdflatex&quot;,            &quot;bibtex&quot;,            &quot;pdflatex&quot;,            &quot;pdflatex&quot;        ]    &#125;],</code></pre><p>当默认以第一种方式编译时，我的环境下是无法识别bib的，解决办法很简单就是使用<code>pdflatex-&gt;bibtex-&gt;pdflatex*2</code>为默认编译链。</p>]]></content>
      
      
      <categories>
          
          <category> VScode使用教程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> VScode.issue </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>希尔伯特空间</title>
      <link href="/2022/04/11/%E4%B8%93%E9%A2%98%E5%AD%A6%E4%B9%A0/%E5%B8%8C%E5%B0%94%E4%BC%AF%E7%89%B9%E7%A9%BA%E9%97%B4/"/>
      <url>/2022/04/11/%E4%B8%93%E9%A2%98%E5%AD%A6%E4%B9%A0/%E5%B8%8C%E5%B0%94%E4%BC%AF%E7%89%B9%E7%A9%BA%E9%97%B4/</url>
      
        <content type="html"><![CDATA[<h3 id="等量变换"><a href="#等量变换" class="headerlink" title="等量变换"></a>等量变换</h3><p><strong>概率场景：</strong></p><p>由于概率分布的积分对应面积为1，所以在微分角度上，两个分布的变化量是相等的，则有：<br>$$<br>p(x)dx&#x3D;p(y)dy \<br>p(y)&#x3D;p(x)\left|\frac{dx}{dy}\right|<br>$$</p><span id="more"></span><h3 id="Hilbert-Space-希尔伯特空间"><a href="#Hilbert-Space-希尔伯特空间" class="headerlink" title="Hilbert Space 希尔伯特空间"></a>Hilbert Space 希尔伯特空间</h3><p>线性空间（向量空间）关注的是向量的位置，对于一个线性空间，知道<code>基</code>（相当于三维空间中的坐标系）便可确定空间中元素的坐标（即位置）；线性空间只定义了<code>加法和数乘</code>运算。</p><ul><li><p>赋范线性空间：如果我们想知道向量的长度，定义<code>范数</code></p></li><li><p>度量空间：如果我们想知道向量间的距离，定义<code>距离</code></p></li><li><p>内积空间：如果我们想知道向量的夹角，定义<code>内积</code></p></li><li><p>欧式空间：定义了内积的有限维实线性空间</p><blockquote><p>有限维：设$A$是线性空间$E$的一个线性无关子集，我们设$A$的维度为$D_E$。当$D_E&lt; +\infty$时，称$E$为有限维的，否则称$E$为无限维的，即欧式空间中没有无限维的计算的概念  </p></blockquote></li><li><p>完备空间：如果我们想研究收敛性（极限），定义<code>完备</code></p><blockquote><p>完备性：是在极限的基础上衍生的概念。例如在有理数集上的一个序列{1，1.4，1.41，1.414，1.4142…}，可知此序列极限为2根号2，而根号2为无理数，不属于有理数集，即有理数集不具备完备性，也就是有理数集不具备极限的概念，因为有理数集上的数都是确定的</p></blockquote></li><li><p>Banach空间：完备的赋范线性空间</p></li><li><p><kbd>Hilbert空间</kbd>：完备的内积空间（极限运算中不能跑出度量的范围；是欧式空间的一种推广；由于极限计算针对的一般是函数，所以Hilbert空间一般是指函数空间，可以定义函数的內积）</p><blockquote><p>函数的內积：我们有两个函数$f(x)$与$g(x)$与区间$[a,b]$，且两函数在该区间上可积且平方可积。则积分：$\int_a^b f(x)g(x)dx$，我们称之为函数的内积，函数的内积常记作$&lt;f(x),g(x)&gt;$，如果是离散的函数则我们可以直接：$\sum{f(x)\times g(x)}$，用矩阵表示就是$F(X)G(X)$</p></blockquote></li></ul><p>希尔伯特空间是一个完备的空间，其上所有的<code>柯西列</code>等价于<code>收敛列</code>，从而微积分中的大部分概念都可以无障碍地推广到希尔伯特空间中。</p><blockquote><p><strong>柯西序列</strong><br>定义：在具有度量$d$的度量空间$S$中，一个序列为柯西序列，若其符合以下条件：<br>对于任意的实数$\epsilon &gt; 0$，存在一正整数$N$，使得每当$m,n&gt;N$时都有$d(a_m, a_n)&lt;\epsilon$</p><p>在数学中，一个柯西列是指一个这样一个序列，它的元素随着序数的增加而愈发靠近。更确切地说，在去掉有限个元素后，可以使得余下的元素中任何两点间的距离的最大值不超过任意给定的正的常数。</p><p>柯西列的定义依赖于距离的定义，所以只有在度量空间(metric space)中柯西列才有意义。在更一般的一致空间(uniform space)中，可以定义更为抽象的柯西滤子(Cauchy filter)和柯西网(Cauchy net)。</p><p>柯西序列的重要作用是定义“完备空间”。完备空间是指一种度量空间，它的所有柯西序列（如果有的话），都收敛在这个空间自己里面。</p><p>在完备空间（complete space）中，所有的柯西列都有极限，这就让人们可以在不求出这个极限（如果存在）的情况下，利用柯西列的判别法则证明该极限是存在的。柯西列在构造具有完备性的代数结构的过程中也有重要价值，如构造实数。</p><p>1.对于在某度量空间内的柯西序列，它的极限不一定在相同的度量空间内。如有理柯西序列可导出无理极限。（事实上，一种实数构造就是用这种方法）</p><p>2.任何收敛列必然是柯西列，任何柯西列必然是有界序列。</p></blockquote><p>希尔伯特空间为基于任意正交系上的多项式表示的傅立叶级数和傅立叶变换提供了一种有效的表述方式，而这也是泛函分析的核心概念之一。</p><img src="/images/v2-be26b2ba1df2edc9636647a28b22238d_1440w.jpg" alt="空间关系图" style="zoom:80%;" /><p><strong>Reproducing Kernel Hilbert Space再生核希尔伯特空间：</strong></p><p><kbd>Kernel</kbd>任何半正定的函数都可以作为核函数（Merrcer定理：充要条件）</p><blockquote><p><strong>Merrcer定理：</strong>所谓半正定函数$f(x_i, x_j)$，是指拥有训练数据集合$(x_1, x_2,\dots,x_n)$，我们定义一个矩阵的元素$a_{ij}&#x3D;f(x_i, x_j)$，这个矩阵是半正定的，那么$f(x_i, x_j)$就成为半正定的函数。</p></blockquote><p>再生核希尔伯特空间是支持监督学习（SVM）等监督学习模型的理论基础，实际上再生核希尔伯特空间就是是由核函数构成的希尔伯特空间，这里的再生指的是再生性，这里的核函数比如LibSVM中自带的几类：</p><ol><li>线性：$K(v_1,v_2)&#x3D;&lt;v_1,v_2&gt;$</li><li>多项式：$K(v_1,v_2)&#x3D;(\gamma&lt;v_1,v_2&gt;+c)^n$</li><li>高斯核：$K(v_1,v_2)&#x3D;\exp(-\gamma|v_1-v_2|^2)$</li><li>Sigmoid：$K(v_1,v_2)&#x3D;\tanh(\gamma&lt;v_1,v_2&gt;+c)$</li></ol><blockquote><p>设$\mathcal{X}$是输入空间(欧式空间$R^n$的子集或离散集合)，又设$\mathcal{H}$是特征空间(希尔伯特空间)，如果存在一个$\mathcal{X}$到$\mathcal{H}$的映射$\phi(x):\mathcal{X}\rightarrow\mathcal{H}$使得对所有$x,z\in\mathcal{X}$，函数$K(x,z)$满足条件$K(x,z)&#x3D;\phi(x)\cdot\phi(z)$则称$K(x,z)$为核函数，$\phi(x)$为映射函数，式中$\phi(x)\cdot\phi(z)$为$\phi(x)$和$\phi(z)$的內积。</p></blockquote><p>再生性指的就是<strong>原本函数之间计算内积需要算无穷维的积分（也就是这个映射函数可以映射到高维甚至无穷维（高斯核），而计算无穷维的积分是非常复杂的），但是现在只需要算核函数可以。</strong></p>]]></content>
      
      
      <categories>
          
          <category> 专题学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 学习笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>科学空间笔记</title>
      <link href="/2022/04/11/%E4%B8%93%E9%A2%98%E5%AD%A6%E4%B9%A0/%E7%A7%91%E5%AD%A6%E7%A9%BA%E9%97%B4%E7%AC%94%E8%AE%B0/"/>
      <url>/2022/04/11/%E4%B8%93%E9%A2%98%E5%AD%A6%E4%B9%A0/%E7%A7%91%E5%AD%A6%E7%A9%BA%E9%97%B4%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<h2 id="关于VAE"><a href="#关于VAE" class="headerlink" title="关于VAE"></a>关于VAE</h2><h2 id="关于Flow"><a href="#关于Flow" class="headerlink" title="关于Flow"></a>关于Flow</h2><p><strong>缺点</strong></p><p><code>由于必须保证逆变换简单和雅可比行列式容易计算，那么每一层的非线性变换能力都很弱。所以为了保证充分的拟合能力，模型就必须堆得非常深，计算量非常大。</code></p><span id="more"></span><h2 id="余弦相似度的假设"><a href="#余弦相似度的假设" class="headerlink" title="余弦相似度的假设"></a><a href="https://kexue.fm/archives/8069">余弦相似度的假设</a></h2><p>$$<br>cos(x,y)&#x3D;\frac{\sum^d_{i&#x3D;1}{x_iy_i}}{\sqrt{\sum^d_{i&#x3D;1}{x^2_i}}\sqrt{\sum^d_{i&#x3D;1}{y^2_i}}}<br>$$</p><blockquote><p>上式等号只在<strong>标准正交基下成立</strong>。向量的“夹角余弦”本身是具有鲜明的几何意义的，但上式右端只是坐标的运算，坐标依赖于所选取的坐标基，基底不同，内积对应的坐标公式就不一样，从而余弦值的坐标公式也不一样。</p></blockquote><p><strong>如果用公式算余弦值来比较句子相似度时表现不好，那么原因可能就是此时的句向量所属的坐标系并非标准正交基。</strong></p><p>原则上我们无法确定此时向量所属坐标系，但是我们在给向量集合选择基底时，可以依据猜测：<code>会尽量地用好每一个基向量，从统计学的角度看，这就体现为每个分量的使用都是独立的、均匀的，如果这组基是标准正交基，那么对应的向量集应该表现出“各项同性”来。</code>【<strong>如果一个向量的集合满足各向同性，那么我们可以认为它源于标准正交基</strong>】</p><p><strong>标准化协方差矩阵</strong></p><p>标准正态分布的均值为0、协方差矩阵为单位阵。假设向量集合${x_i}^N_{i&#x3D;1}$执行变换$\hat{x}<em>i&#x3D;(x_i-\mu)W$使得${\hat{x}<em>i}^N</em>{i&#x3D;1}$的均值为0，协方差矩阵为单位阵，这个操作对应于数据挖掘中的白化操作(Whitening)，具体如下：<br>$$<br>均值为0则：\mu&#x3D; \frac{1}{N}\sum</em>{i&#x3D;1}^Nx_i\<br>原始协方差：\Sigma&#x3D;\frac{1}{N}\sum_{i&#x3D;1}^N(x_i-\mu)^T(x_i-\mu)&#x3D;\left(\frac{1}{N}\sum_{i&#x3D;1}^N{x^T_ix_i}\right)-\mu^T\mu \<br>变换后协方差：\hat\Sigma&#x3D;W^T\Sigma W&#x3D;I\rightarrow\Sigma&#x3D;(W^T)^{-1}W^{-1}&#x3D;(W^{-1})^TW^{-1}\<br>协方差矩阵是半正定对称矩阵，可以被SVD分解：\Sigma&#x3D;U\Lambda U^T\rightarrow W^{-1}&#x3D;\sqrt{\Lambda}U^T\rightarrow W&#x3D;U\sqrt{\Lambda^{-1}}<br>$$</p><h2 id="关于Attention"><a href="#关于Attention" class="headerlink" title="关于Attention"></a>关于Attention</h2><pre><code>RNN因其本质是马尔科夫决策过程，无法很好的学习全局信息。CNN方便并行，而且容易捕捉到一些全局的结构信息。RNN要逐步递归才能获得全局信息，因此一般要双向RNN才比较好：$y_t=f(y_&#123;t-1&#125;,x_t)$CNN事实上只能获取局部信息，是通过层叠来增大感受野：$y_t=f(x_&#123;t-1&#125;,x_t,x_&#123;t+1&#125;)$ [3x的kernel]</code></pre><p>Attention的思路最为粗暴，它一步到位获取了全局信息！它的解决方案是：$y_t&#x3D;f(x_t,A,B)$ A和B是额外引入的序列，如果$A&#x3D;B&#x3D;X$就是self-attention。Attention的意思是直接将$x_t$与原来的每个词进行比较，最后算出$y_t$。<br>$$<br>Attention(Q,K,V)&#x3D;softmax(\frac{QK^T}{\sqrt{d_k}})V<br>$$<br>$Q\in R^{n\times d_k}$，$K\in R^{m\times d_k}$，$V\in R^{m\times d_v}$。如果忽略激活函数softmax的话，那么事实上它就是三个矩阵相乘，最后的结果就是一个$n\times d_v$的矩阵。于是我们可以认为：这是一个Attention层，将序列Q编码成了一个新的的序列。事实上$Q,K,V$分别是$query,key,value$的简写，那么上式的意思就是通过$query$与各个$key$内积的并softmax的方式，来得到$query$与各个$value$的相似度，然后加权求和，得到一个向量。其中因子$d_k$起到调节作用，使得内积不至于太大（太大的话softmax后就非0即1了，不够“soft”了）。</p><pre><code>50维的词向量，将每一维打乱重新排个序（当然整体要按同样的顺序来重新排序），它还是等价于原来的词向量。既然相加的对象（词向量）都没有局部结构，我们也没必要强调被加的对象（Position_Embedding）的局部结构（也就是交叉连接）了。</code></pre><h2 id="一些观点"><a href="#一些观点" class="headerlink" title="一些观点"></a>一些观点</h2><pre><code>数据扩增是将我们的先验知识融入到模型中的一种方案。mixup相当于一个正则项，它希望模型尽可能往线性函数靠近，也就是说，既保证模型预测尽可能准确，又让模型尽可能简单。</code></pre>]]></content>
      
      
      <categories>
          
          <category> 专题学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 学习笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>高斯分布</title>
      <link href="/2022/04/11/%E4%B8%93%E9%A2%98%E5%AD%A6%E4%B9%A0/%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%83/"/>
      <url>/2022/04/11/%E4%B8%93%E9%A2%98%E5%AD%A6%E4%B9%A0/%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%83/</url>
      
        <content type="html"><![CDATA[<h3 id="单变量高斯分布-univariate-Gaussian"><a href="#单变量高斯分布-univariate-Gaussian" class="headerlink" title="单变量高斯分布(univariate Gaussian )"></a>单变量高斯分布(univariate Gaussian )</h3><p>$$<br>f(x)&#x3D;\frac{1}{\sqrt{2 \pi} \sigma} \exp \left(-\frac{(x-\mu)^{2}}{2 \sigma^{2}}\right)<br>$$</p><span id="more"></span><h3 id="单高斯分布"><a href="#单高斯分布" class="headerlink" title="单高斯分布"></a>单高斯分布</h3><p>$$<br>N(x ; u, \Sigma)&#x3D;\frac{1}{\sqrt{2 \pi}|\Sigma|} \exp \left[-\frac{1}{2}(x-u)^{T}\Sigma^{-1} (x-u)\right]<br>$$</p><p>单高斯与单变量高斯的区别在于前者维度为$d$，后者维度为$1$。对于单高斯模型，$\mu$通常代表训练样本的均值，$\Sigma$代表样本的方差。</p><h3 id="高斯混合模型（GMM）"><a href="#高斯混合模型（GMM）" class="headerlink" title="高斯混合模型（GMM）"></a>高斯混合模型（GMM）</h3><p>$$<br>\operatorname{Pr}(x)&#x3D;\Sigma_{k&#x3D;1}^{K} \pi_{k} N\left(x ; u_{k}, \Sigma_{k}\right)<br>$$</p><p>依据全概率公式，$\pi_{k}$是选中参数$u_{k}$和$\Sigma_{k}$的概率，又称权重因子。EM算法用于优化GMM。</p>]]></content>
      
      
      <categories>
          
          <category> 专题学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 学习笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>第5章 决策树</title>
      <link href="/2022/04/10/%E3%80%8A%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E3%80%8B%EF%BC%88%E7%AC%AC%E4%BA%8C%E7%89%88%EF%BC%89/%E7%AC%AC5%E7%AB%A0%20%E5%86%B3%E7%AD%96%E6%A0%91/"/>
      <url>/2022/04/10/%E3%80%8A%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E3%80%8B%EF%BC%88%E7%AC%AC%E4%BA%8C%E7%89%88%EF%BC%89/%E7%AC%AC5%E7%AB%A0%20%E5%86%B3%E7%AD%96%E6%A0%91/</url>
      
        <content type="html"><![CDATA[<p>决策树（decision tree）是一种基本的分类和回归方法，它可以任务是if-then规则（<strong>互斥且完备</strong>）的集合，也可以认为是定义在特征空间与类空间上的条件概率分布。<br>因为从所有可能的决策树中选取最优决策树是NP完全问题，所以现实中决策树学习算法通常采用启发式方法，近似求解这一最优化问题，得到的决策树是sub-optimal的。<br>决策树的生成对应于模型的局部选择<code>局部最优</code>，决策树的剪枝对应于模型的全局选择<code>全局最优</code>。</p><span id="more"></span><h3 id="1-特征选择"><a href="#1-特征选择" class="headerlink" title="1. 特征选择"></a>1. 特征选择</h3><p>特征现在在于选取对训练数据具有分类能力的特征，通常特征选择的准则是信息增益或信息增益比。<br><strong>熵</strong><br>熵（entropy）是表示随机变量不确定性的度量：$H(X)&#x3D;-\sum_i^N{p_i\log{p_i}},\ 0\le{H(p)\le\log{n}}$<br>条件熵（conditional entropy）表示在已知随机变量X的条件下随机变量Y的不确定性：$H(Y|X)&#x3D;\sum_i^N{p_iH(Y|X&#x3D;x_i)}$</p><p><strong>信息增益</strong>（Information gain）表示得知特征X的信息而使得类Y的信息的确定性减少的程度：<br>$g(D,A)&#x3D;H(D)-H(D|A)$<br>上式中$H(D)[empirical\ entropy]$表示对数据集D进行分类的不确定性，$H(D|A)[empirical\ comditional\ entropy]$表示在特征A给定的条件下对数据集D进行分类的不确定性。一般地，熵与条件熵的差称为互信息（mutual Information）。决策树学习中的信息增益等价于训练数据集中类与特征的互信息。</p><p><strong>信息增益比</strong>（Information gain ratio）信息增益存在偏向于选择取值较多的特征，ratio可以避免此问题。<br>$g_R(D,A)&#x3D;\frac{g(D,A)}{H_A(D)},\ H_A(D)&#x3D;-\sum_{i&#x3D;1}^n\frac{|D_i|}{|D|}\log_2\frac{|D_i|}{|D|},\ n是特征A的取值个数$</p><h3 id="2-决策树的生成"><a href="#2-决策树的生成" class="headerlink" title="2. 决策树的生成"></a>2. 决策树的生成</h3><p><strong>ID3：</strong>核心是在决策树各个结点上应用信息增益准则选择特征，递归地构建决策树。ID3相当于用极大似然法进行概率模型的选择。<strong>C4.5：</strong>改进ID3，并使用信息增益比。</p><h3 id="3-决策树的剪枝（pruning）"><a href="#3-决策树的剪枝（pruning）" class="headerlink" title="3. 决策树的剪枝（pruning）"></a>3. 决策树的剪枝（pruning）</h3><p>决策树的剪枝往往通过极小化决策树整体的损失函数（loss function）或代价函数（cost function）来实现。<br>设树$T$的叶结点个数为$|T|$，$t$是树$T$的叶结点，该结点有$N_t$个样本点，其中$k$类样本点有$N_{tk}$个，则决策树学习的损失函数可以定义为：<br>$C_\alpha(T)&#x3D;\sum_t^{|T|}N_tH_t(T)+\alpha|T|&#x3D;C(T)+\alpha|T|\ H_t(T)&#x3D;-\sum_k\frac{N_{tk}}{N_t}\log\frac{N_{tk}}{N_t}\C(T)&#x3D;\sum_t^{|T|}{N_tH_t(T)&#x3D;-\sum_t^{|T|}\sum_k^K{N_{tk}}\log\frac{N_{tk}}{N_t}}$<br>$C(T)$表示模型对训练数据的预测误差（模型与训练数据的拟合程度），$|T|$表示模型复杂度，$\alpha\ge0$控制两者间的影响。较大的$\alpha$促使选择较简单的模型，较小的$\alpha$促使选择较复杂的模型，$\alpha&#x3D;0$意味着只考虑模型与训练数据的拟合程度，不考虑模型的复杂度。剪枝就是当$\alpha$确定时，选择损失函数最小的模型。损失函数的极小化等价于正则化的极大似然估计。</p><blockquote><p><strong>输入：</strong>生成算法产生的整个树$T$，参数$\alpha$<br><strong>输出：</strong>修剪后的子树$T_{\alpha}$<br>1-计算每个结点的经验熵<br>2-递归地从树的叶结点向上回缩<br>3-根据回缩前B后A损失函数值$C_{\alpha}(T_A)\le C_{\alpha}(T_B)$，剪掉后损失减少则剪枝（重复）</p></blockquote><h3 id="4-CART算法"><a href="#4-CART算法" class="headerlink" title="4. CART算法"></a>4. CART算法</h3><p>分类与回归树（CART）是在给定输入随机变量X条件下输出随机变量Y的条件概率分布。（左是右否的二叉树）</p><blockquote><p><strong>生成：</strong>基于训练数据集生成决策树，生成的树要尽量大。<br><strong>剪枝：</strong>用验证集对已生成的树进行剪枝并选择最优子树，用损失函数最小作为剪枝的标准。</p></blockquote><p><strong>CART生成</strong><br><code>回归树：</code>平方误差最小化准则<br><code>分类树：</code>基尼指数最小化准则</p><blockquote><p><strong>最小二乘回归树生成算法</strong><br><strong>输入：</strong> 训练数据集$D$<br><strong>输出：</strong> 回归树$f(x)$<br>在训练数据集所在的输入空间中，递归地将每个区域划分为两个子区域并决定每个子区域上的输出值，构建二叉树：1-选择最优切分变量$j$与切分点$s$，求解$\min_{j,s}[\min_{c_1}\sum_{x_i\in R_1(j,s)}(y_i-c_1)^2+\min_{c_2}\sum_{x_i\in R_2(j,s)}(y_i-c_2)^2]$遍历变量$j$对固定的切分变量$j$扫描切分点$s$选择使式达到最小值的对$(j,s)$。2-用选定的$(j,s)$划分区域并决定相应的输出值$R_1(j,s)&#x3D;{x|x^{(j)}\le s},\ \ R_2(j,s)&#x3D;{x|x^{(j)}\gt s},\ \ \hat{c}<em>m&#x3D;\frac{1}{N_m}\sum</em>{x_i\in R_m(j,s)}y_i,x\in R_m$。3-重复1、2。4-将输入空间划分为$M$个区域$R_1,R_2,\cdots,R_M$生成决策树：$f(x)&#x3D;\sum_m^M\hat{c}_mI(x\in R_m)$</p><p><strong>基尼指数分类树生成算法</strong><br><strong>输入：</strong> 训练数据集$D$，停止计算的条件<br><strong>输出：</strong> CART决策树<br>从根结点开始构建二叉树：1-设结点的训练数据集为$D$，计算现有特征对数据集的基尼指数$Gini(D)$。 根据特征$A&#x3D;a$将数据集分成$D_1$和$D_2$计算基尼指数$Gini(D,A)$。2-在所有特征与切分点对$&lt;A,a&gt;$中选择基尼指数最小的作为最优特征与最优切分点，由此生成两个子结点。3-重复1，2，直到满足停止条件。4-生成CART树。</p><p><code>基尼指数：</code>$K$类中样本点属于第$k$类的概率为$p_k$，则概率分布的基尼指数为：$Gini(p)&#x3D;\sum_k^K{p_k(1-p_k)}&#x3D;1-\sum_k^K{p_k^2}$。对于给定样本集合$D$，基尼指数为$Gini(D)&#x3D;1-\sum_k^K(\frac{|C_k|}{|D|})^2$，对于在特征$A$条件下的集合$D$的基尼指数为$Gini(D,A)&#x3D;\frac{|D_1|}{|D|}Gini(D_1)+\frac{|D_2|}{|D|}Gini(D_2)$。基尼指数越大，样本集合的不确定性也越大（与熵类似）。<br><code>排列组合：</code>排列$A_n^m&#x3D;\frac{n!}{(n-m)!}$， 组合$C_n^m&#x3D;\pmatrix{\begin{matrix}n\m\end{matrix}}&#x3D;\frac{A_n^m}{m!}&#x3D;\frac{n!}{m!(n-m)!}&#x3D;C(n,m)&#x3D;C(n,n-m)$<br><code>二项式定理：</code>$(a+b)^n&#x3D;\sum_i^nC_n^i a^{n-i}b^i$，$C_n^i$杨辉三角<br><code>伯努利分布：</code>关于布尔变量$x\in{0,1}$的概率分布，其连续参数$p\in[0,1]$表示变量$x&#x3D;1$的概率：$p(x)&#x3D;p^x(1-p)^{1-x},E(x)&#x3D;p,\sigma&#x3D;p(1-p)$<br><code>二项分布：</code>1-实验次数固定为$n$；2-每次事件只有两种可能；3-每次成功的概率固定为$p$；4-表示成功$x$次的概率：$p(x)&#x3D;C_n^x p^x(1-p)^{n-x},E(x)&#x3D;np,\sigma&#x3D;\sqrt{np(1-p)}$<br><code>几何分布：</code>0-与二项分类相似，唯一不同在于4-表示进行$x$次尝试，取得第一次成功的概率：$p(x)&#x3D;(1-p)^{x-1}p,E(x)&#x3D;1&#x2F;p,\sigma&#x3D;(1-p)&#x2F;p^2$<br>&#96;&#96;泊松分布：&#96;1-事件独立；2-在任意相同的时间范围内，事件发生的概率相同；3-在某个时间范围内，发生某件事情$x$的概率：$p(x)&#x3D;\frac{u^xe^{-u}}{x!},E(x)&#x3D;\sigma&#x3D;u\ [p&#x3D;\frac{u}{n},p(x)&#x3D;\lim_{n\rightarrow\infty}\pmatrix{\begin{matrix}n\m\end{matrix}}p^x(1-p)^{n-x}]即在p上的极限$</p><p><code>伯努利扔一次硬币；二项分布是多次伯努利；泊松分布是p很小的二项，即无数次扔硬币且正面概率极小；正态分布是n很大的二项，即无数次扔硬币且硬币完全相同。</code></p></blockquote><p><strong>CART剪枝</strong></p><blockquote><p><strong>输入：</strong> CART算法完全生成的决策树$T_0$<br><strong>输出：</strong> 最优决策树$T_\alpha$<br>1-设$k&#x3D;0,T&#x3D;T_0,\alpha&#x3D;+\infty$<br>2-自下而上地对各内部结点$t$计算$C(T_t)$，$|T_t|$以及$g(t)&#x3D;\frac{C(t)-C(T_t)}{|T_t|-1},\alpha&#x3D;\min(\alpha,g(t))$。以$|T_t|$为叶结点个数$t$为根节点的子树$T_t$，对训练数据的预测误差$C(T_t)$。<br>3-对$g(t)&#x3D;\alpha$的内部结点$t$进行剪枝，并对叶结点以多数表决法决定其类，得到树$T$。<br>4-设$k&#x3D;k+1,T_k&#x3D;T,\alpha_k&#x3D;\alpha$<br>5-如果$T_k$不是由根节点及两个叶结点构成的树，则回到1-$\alpha&#x3D;+\infty$；否则令$T_k&#x3D;T_n$<br>6-采用交叉验证法在子树序列$T_0,T_1,\cdots,T_n$中选取最优子树$T_{\alpha}$。</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 《统计学习方法》（第二版） </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 学习笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>第3章 K近邻法</title>
      <link href="/2022/04/10/%E3%80%8A%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E3%80%8B%EF%BC%88%E7%AC%AC%E4%BA%8C%E7%89%88%EF%BC%89/%E7%AC%AC3%E7%AB%A0%20K%E8%BF%91%E9%82%BB%E6%B3%95/"/>
      <url>/2022/04/10/%E3%80%8A%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E3%80%8B%EF%BC%88%E7%AC%AC%E4%BA%8C%E7%89%88%EF%BC%89/%E7%AC%AC3%E7%AB%A0%20K%E8%BF%91%E9%82%BB%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<h3 id="3-1-k-近邻算法-（-k-nearest-neighbor-KNN）"><a href="#3-1-k-近邻算法-（-k-nearest-neighbor-KNN）" class="headerlink" title="3.1 $k$近邻算法 （$k$-nearest neighbor, KNN）"></a>3.1 $k$近邻算法 （$k$-nearest neighbor, KNN）</h3><blockquote><p><strong>输入：</strong> 训练集$T&#x3D;{(x_1,y_1),(x_2,y_2),\cdots,(x_N,y_N)}$<br><strong>输出：</strong> 实例$x$所属类别$y$<br>1-根据给定的距离度量，在训练集$T$中找出与$x$最近邻的$k$个点，涵盖这$k$个点的$x$的领域记作$N_k(x)$;<br>2-在$N_k(x)$中根据分类决策规则决定$x$的类别$y$：$y&#x3D;\arg\max_{c_j}\sum_{x_i\in N_k(x)}{I(y_i&#x3D;c_j)}$，$I$为指示函数。</p></blockquote><p>是一种基本分类与回归方法，没有显式的学习过程</p><span id="more"></span><h3 id="3-2-k-近邻模型"><a href="#3-2-k-近邻模型" class="headerlink" title="3.2 $k$近邻模型"></a>3.2 $k$近邻模型</h3><p>$k$近邻算法使用的模型实际上对应于对特征空间的划分，模型有三个基本要素：距离度量、$k$值得选择和分类决策规则。</p><p><strong>距离度量</strong></p><blockquote><p>欧式距离、$L_p$距离（Minkowski距离）</p><p>$L_p(x_i,y_i)&#x3D;(\sum_{l&#x3D;1}^n|x_i^{(l)}-x_j^{(l)}|^p)^\frac{1}{p},p\ge1$<br>$p&#x3D;2$，欧式距离；$p&#x3D;1$，Manhattan距离；$p&#x3D;\infty$，各个坐标距离的最大值</p></blockquote><p><strong>$k$值的选择</strong></p><blockquote><p><strong>较小值：</strong> 相当于在较小邻域中训练实例进行预测，近似误差会减小，估计误差会增大，对近邻点非常敏感。<u><em>k值减小意味着整体模型变得复杂，容易过拟合。</em></u></p><p><strong>较大值：</strong> 相当于在较大邻域中训练实例进行预测，估计误差会减小，近似误差会增大，对远邻点依然有效，容易误检。<u><em>k值增大意味着整体模型变得简单，容易欠拟合。</em></u></p><p>$\mathbf{k&#x3D;N}$：无论什么输入实例是什么，都将简单地预测它属于在训练实例中最多的类。这时，模型过于简单，完全忽略了实例中大量有用信息。</p></blockquote><h3 id="3-3-k-近邻法的实现：-kd-树"><a href="#3-3-k-近邻法的实现：-kd-树" class="headerlink" title="3.3 $k$近邻法的实现：$kd$树"></a>3.3 $k$近邻法的实现：$kd$树</h3><p>以特征$x$的第一维为坐标轴，以中位数为切分点，然后是第二维，第三维，划分得到最后的二叉树。</p>]]></content>
      
      
      <categories>
          
          <category> 《统计学习方法》（第二版） </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 学习笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>第4章 朴素贝叶斯法</title>
      <link href="/2022/04/10/%E3%80%8A%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E3%80%8B%EF%BC%88%E7%AC%AC%E4%BA%8C%E7%89%88%EF%BC%89/%E7%AC%AC4%E7%AB%A0%20%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%B3%95/"/>
      <url>/2022/04/10/%E3%80%8A%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E3%80%8B%EF%BC%88%E7%AC%AC%E4%BA%8C%E7%89%88%EF%BC%89/%E7%AC%AC4%E7%AB%A0%20%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<h3 id="1-基本方法"><a href="#1-基本方法" class="headerlink" title="1.基本方法"></a>1.基本方法</h3><p>朴素贝叶斯法（naive Bayes）是基于贝叶斯定理与特征条件独立假设的分类法。对于给定的训练数据集，首先基于特征条件独立假设学习输入输出的联合概率分布；然后基于此模型，对给定的输入$x$，利用贝叶斯定理求出后验概率最大的输出$y$.</p><span id="more"></span><p>先学习先验概率分布$P(Y&#x3D;c_k)$及条件概率分布$P(X&#x3D;x|Y&#x3D;c_k)&#x3D;P(X^{(1)}&#x3D;x^{(1)},X^{(2)}&#x3D;x^{(2)},\cdots,X^{(N)}&#x3D;x^{(n)}|Y&#x3D;c_k)$从而得到联合概率分布$P(X,Y)$<br>由于条件概率分布有指数级数量的参数，所以对条件概率分布做了<strong>条件独立性假设</strong><code>用于分类的特征在类确定的条件下都是条件独立的</code>：$P(X&#x3D;x|Y&#x3D;c_k)&#x3D;P(X^{(1)}&#x3D;x^{(1)},X^{(2)}&#x3D;x^{(2)},\cdots,X^{(N)}&#x3D;x^{(n)}|Y&#x3D;c_k)&#x3D;\prod_{j&#x3D;1}^n{P(X^j&#x3D;x^j|Y&#x3D;c_k)}$<br>分类器：$y&#x3D;f(x)&#x3D;\arg\max_{c_k}\frac{P(Y&#x3D;c_k)\Pi_{j}P(X^{j}&#x3D;x^j|Y&#x3D;c_k)}{\sum_k{P(Y&#x3D;c_k)\Pi_{j}P(X^{j}&#x3D;x^j|Y&#x3D;c_k)}}$</p><p><strong>后验概率最大化的含义</strong></p><p>期望风险最小化准则变为了后验概率最大化准则<br>$$<br>\begin{align}<br>f(x)&amp;&#x3D;\arg\min_{y\in\mathcal{Y}}\sum_{k&#x3D;1}^K{L(c_k,y)P(c_k|X&#x3D;x)}\<br>&amp;&#x3D;\arg\min_{y\in\mathcal{Y}}\sum_{k&#x3D;1}^K{P(y\neq c_k|X&#x3D;x)}\<br>&amp;&#x3D;\arg\min_{y\in\mathcal{Y}}{(1-P(y&#x3D;c_k|X&#x3D;x))}\<br>&amp;&#x3D;\arg\max_{y\in\mathcal{Y}}{P(y&#x3D;c_k|X&#x3D;x)}\<br>\end{align}<br>$$</p><h3 id="2-朴素贝叶斯法的参数估计"><a href="#2-朴素贝叶斯法的参数估计" class="headerlink" title="2.朴素贝叶斯法的参数估计"></a>2.朴素贝叶斯法的参数估计</h3><p><strong>极大似然估计</strong></p><p>估计先验概率：$P(Y&#x3D;c_k)&#x3D;\frac{\sum_{i&#x3D;1}^N{I(y_i&#x3D;c_k)}}{N},I为指示函数$<br>估计条件概率：$P(X^j&#x3D;a_{jl}|Y&#x3D;c_k)&#x3D;\frac{\sum_{i&#x3D;1}^{N}{I(x_i^j&#x3D;a_{jl},y_i&#x3D;c_k)}}{\sum_{i&#x3D;1}^{N}{I(y_i&#x3D;c_k)}}$<br>会出现所有估计概率值为0的情况</p><p><strong>贝叶斯估计</strong></p><p>估计先验概率：$P_\lambda(Y&#x3D;c_k)&#x3D;\frac{\sum_{i&#x3D;1}^N{I(y_i&#x3D;c_k)}+\lambda}{N+K\lambda},I为指示函数$<br>估计条件概率：$P_\lambda(X^j&#x3D;a_{jl}|Y&#x3D;c_k)&#x3D;\frac{\sum_{i&#x3D;1}^N{I(x_i^j&#x3D;a_{jl},y_i&#x3D;c_k)+\lambda}}{\sum_{i&#x3D;1}^N{I(y_i&#x3D;c_k)+S_j\lambda}}$<br>$\lambda&#x3D;0$就是<code>极大似然估计</code>，$\lambda&#x3D;1$就是<code>拉普拉斯平滑</code></p>]]></content>
      
      
      <categories>
          
          <category> 《统计学习方法》（第二版） </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 学习笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>第2章 感知机</title>
      <link href="/2022/04/10/%E3%80%8A%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E3%80%8B%EF%BC%88%E7%AC%AC%E4%BA%8C%E7%89%88%EF%BC%89/%E7%AC%AC2%E7%AB%A0%20%E6%84%9F%E7%9F%A5%E6%9C%BA/"/>
      <url>/2022/04/10/%E3%80%8A%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E3%80%8B%EF%BC%88%E7%AC%AC%E4%BA%8C%E7%89%88%EF%BC%89/%E7%AC%AC2%E7%AB%A0%20%E6%84%9F%E7%9F%A5%E6%9C%BA/</url>
      
        <content type="html"><![CDATA[<h3 id="2-1-感知机模型"><a href="#2-1-感知机模型" class="headerlink" title="2.1 感知机模型"></a>2.1 感知机模型</h3><p>$$<br>f(x)&#x3D;sign(w\cdot x+b),\ sign(x)&#x3D;\begin{cases}+1,x\ge0\-1,x\lt0\end{cases}<br>$$</p><p>对于特征空间$\mathbf{R}^n$中的一个超平面$S$，其中$w$是超平面的法向量，$b$是超平面的截距。</p><span id="more"></span><h3 id="2-2-感知机学习策略"><a href="#2-2-感知机学习策略" class="headerlink" title="2.2 感知机学习策略"></a>2.2 感知机学习策略</h3><ul><li>数据集的线性可分性</li><li>损失函数是参数$w$和$b$连续可导函数：点到超平面的距离 $\frac{1}{|w|}|w\cdot x_i+b|$</li><li>误分类数据满足：$-y_i(w\cdot x_i+b)\gt0$，$y(w\cdot x+b)$称为样本点的函数间隔</li></ul><h3 id="2-3-感知机学习算法"><a href="#2-3-感知机学习算法" class="headerlink" title="2.3 感知机学习算法"></a>2.3 感知机学习算法</h3><p><strong>原始形式</strong></p><blockquote><p><strong>输入：</strong>数据集、学习率$\eta\ (0\lt\eta\le1)$<br><strong>输出：</strong>$w,b,f(x)&#x3D;sign(w\cdot x+b)$</p><ol><li><p>选取初始值$w_0,b_0$</p></li><li><p>在训练集中选取数据$(x_i,y_i)$</p></li><li><p>如果$y_i(w\cdot x_i+b)\le0$</p><p>$$w\leftarrow w+\eta y_i x_i\<br>b\leftarrow b+\eta y_i$$</p></li><li><p>转至2，直到无误分类点</p></li></ol></blockquote><p>首先任意选取一个超平面，然后用梯度下降法不断极小化目标函数，在一个过程中一次随机选取一个误分类点使其梯度下降。</p><p><strong>Novikoff定理</strong></p><ol><li><p>$\exists:y_i(\hat{W}<em>{opt}\cdot\hat{x}<em>i)&#x3D;y_i(W</em>{opt}\cdot x_i+b</em>{opt})\ge\gamma,|\hat{W}_{opt}|&#x3D;1$</p></li><li><p>在训练集上的误分类次数$k$满足不等式：$k\le(\frac{R}{\gamma})^2,R&#x3D;\max_{1\le i\le N}|\hat{x}_i|^2$</p></li></ol><p>说明误分类有上界；训练集可分时，原始形式收敛，不可分时，不收敛；2可以近似看成线段划分，即特征空间最多可以划分成K个。</p><p><code>当训练集可分时，感知机学习算法存在无穷多解，由于不同的初始值或不同的迭代顺序而有所不同。</code></p><p><strong>对偶形式</strong></p><blockquote><p><strong>输入：</strong>数据集、学习率$\eta\ (0\lt\eta\le1)$<br><strong>输出：</strong>$\alpha,b,f(x)&#x3D;sign(\sum_{j&#x3D;1}^N\alpha_j y_j x_j\cdot x+b)$</p><ol><li><p>选取初始值$a\leftarrow0,b\leftarrow0$</p></li><li><p>在训练集中选取数据$(x_i,y_i)$</p></li><li><p>如果$y_i(\sum_{j&#x3D;1}^N\alpha_j y_j x_j\cdot x_i+b)\le0$</p></li></ol><p>  $$\alpha_i\leftarrow\alpha_i+\eta\<br>  b\leftarrow b+\eta y_i$$</p><ol start="4"><li>转至2，直到无误分类点</li></ol></blockquote><p><strong>基本思想：</strong>将$w$和$b$表示为实例$x_i$和标记$y_i$的线性组合，通过求解其系数而得到$w$和$b$。实例点更新次数越多，意味着它距离分类超平面越近，也就越难正确分类。对偶形式中训练实例仅以內积$x_j\cdot x_i$的形式出现（Gram矩阵）。</p><h3 id="习题"><a href="#习题" class="headerlink" title="习题"></a>习题</h3><p><strong>1. 为什么感知机不能表示异或</strong></p><p><strong>2. 样本集线性可分的充要条件是正实例点击所构成的凸壳$^1$与负实例所构成的凸壳互不相交</strong></p><p>$^1$设集合$S\subset\mathbf{R}^n$是由$\mathbf{R}^n$中的$k$个点组成的集合，即$S&#x3D;{x_1,x_2,\cdots,x_k}$ 定义$S$的凸壳$conv(S)$为：<br>$$<br>conv(S)&#x3D;\left{x&#x3D;\sum_{i&#x3D;1}^k{\lambda_i x_i}\mid\sum_{i&#x3D;1}^k{\lambda_i&#x3D;1},\lambda_i\ge0,i&#x3D;1,2,\cdots,k\right}<br>$$<br><code>最小凸多边形、点集合的边界所围成的区域、点集的线性组合</code></p>]]></content>
      
      
      <categories>
          
          <category> 《统计学习方法》（第二版） </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 学习笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hexo搭建GitHub个人博客</title>
      <link href="/2022/04/10/Hexo%E6%90%AD%E5%BB%BAGitHub%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/"/>
      <url>/2022/04/10/Hexo%E6%90%AD%E5%BB%BAGitHub%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/</url>
      
        <content type="html"><![CDATA[<h2 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h2><blockquote><ul><li>安装Node.js</li><li>安装Git</li><li>远程连接GitHub</li><li>安装Hexo</li><li>Hexo的本地配置</li><li>博客相关指令</li></ul></blockquote><span id="more"></span><h3 id="安装Node-js"><a href="#安装Node-js" class="headerlink" title="安装Node.js"></a>安装Node.js</h3><blockquote><p>Node.js就是一个用于创建服务器端应用程序的运行系统，它可以轻松构建网络或其他事件驱动的应用程序服务器。</p></blockquote><p>进入<a href="https://nodejs.org/en/download/">Node.js官网</a>下载对应版本的安装包，默认设置安装。<br>安装完成后进入终端检查是否安装成功，按<code>Win+R</code>进入<code>cmd</code>输入<code>node -v</code>和<code>npm -v</code>，如果出现版本号，则证明安装成功。</p><blockquote><p>npm (Node Package Manager) NodeJS包管理和分发工具<br>(<em>可选</em>) - 添加镜像（进入cmd，以阿里为例）<br>npm config set registry <a href="https://registry.npm.taobao.org/">https://registry.npm.taobao.org</a></p></blockquote><h3 id="安装Git"><a href="#安装Git" class="headerlink" title="安装Git"></a>安装Git</h3><blockquote><p>Git是一个开源的分布式版本控制系统，可以有效、高速地处理从很小到非常大的项目版本管理，帮助我们把本地网页上传到Github。</p></blockquote><p>进入<a href="https://git-scm.com/download/win">Git官网</a>下载，默认设置安装。<br>安装完成之后在<code>cmd</code>中使用<code>git --version</code>验证是否安装成功。</p><h3 id="远程连接GitHub"><a href="#远程连接GitHub" class="headerlink" title="远程连接GitHub"></a>远程连接GitHub</h3><p><strong>生成密钥</strong></p><pre><code class="bash"># git bash中设置user.name和user.emailgit config --global user.name &quot;GitHub用户名&quot;git config --global user.email &quot;GitHub注册邮箱&quot;# 生成密钥ssh-keygen -t rsa -C &quot;注册邮箱&quot;# 将公钥id_rsa.pub添加到GitHubgithub -&gt; settings -&gt; ssh and gpg keys# 测试本地连接ssh -T git@github.com</code></pre><h3 id="安装Hexo"><a href="#安装Hexo" class="headerlink" title="安装Hexo"></a>安装Hexo</h3><blockquote><p>Hexo是一款基于Node.js的静态博客框架，依赖少易于安装使用，可以方便的生成静态网页托管在GitHub和Heroku，是搭建博客的首选框架。</p></blockquote><p>进入<code>cmd</code>输入<code>npm</code>安装命令</p><pre><code class="bash"># 安装指令 -g 表示全局安装npm install hexo-cli -g# 验证指令hexo -v</code></pre><h3 id="Hexo的本地配置"><a href="#Hexo的本地配置" class="headerlink" title="Hexo的本地配置"></a>Hexo的本地配置</h3><p><strong>初始化</strong><br>在<code>Git Bash</code>中执行</p><pre><code class="bash"># 创建存放博客文件夹mkdir myBlog# 初始化hexo init myBlog</code></pre><p>看到<code>Start blogging with Hexo</code>则表示初始化成功。<br><strong>部署到GitHub</strong><br>安装必要插件：</p><pre><code class="bash">npm install hexo-deployer-git --save  #安装自动部署Github插件</code></pre><p>修改配置文件<code>_config.yml</code></p><pre><code class="yml"># Deployment## Docs: https://hexo.io/docs/one-command-deploymentdeploy:  type: git  repo: git@github.com:seeyourmind/seeyourmind.github.io  branch: master</code></pre><p><strong>更换主题</strong><br>以aomori为例</p><pre><code class="bash">git clone https://github.com/lh1me/hexo-theme-aomori.git themes/aomori</code></pre><h3 id="博客相关指令"><a href="#博客相关指令" class="headerlink" title="博客相关指令"></a>博客相关指令</h3><blockquote><p><strong>常用指令</strong><br>hexo new post “article title”<br>hexo s<br>hexo clean &amp;&amp; hexo g -s<br>hexo clean &amp;&amp; hexo g -d</p></blockquote><p><strong>文章书写</strong></p><pre><code class="bash">hexo new [layout] &lt;title&gt; 或 hexo n [layout] &lt;title&gt;# layout: #  post(默认，存于source/_posts)#  draft(草稿，存于source/_drafts，可以使用publish指令将其推送到_posts)#  page(页面)-p --path 自定义新文章-r --replece 替换同名文章-s --slug 文章的slug，作为新文章的文件名和发布后的URL# 示例hexo new page --path about/me &quot;About me&quot;</code></pre><p><strong>生成静态文件</strong></p><pre><code class="bash">hexo generate 或 hexo g-d --deploy 文件生成后部署网站-w --watch 监视文件变动-b --bail 生成过程中出现异常时抛出-f --force 强制重新生成文件-c --concurrency 最大同时生成文件数量，默认无限制</code></pre><p><strong>发布草稿</strong></p><pre><code class="bash">hexo publish [layout] &lt;filename&gt;</code></pre><p><strong>启动服务器</strong><br><code>hexo server 或 hexo s</code> 启动服务器，<code>ctrl+c</code> 结束，默认地址为：<a href="http://localhost:4000/">http://localhost:4000/</a><br><strong>部署网站</strong></p><pre><code class="bash">hexo deploy 或 hexo d-g 或--generate 部署之前写成静态文件</code></pre><p><strong>渲染文件</strong></p><pre><code class="bash">hexo render &lt;file1&gt; [file2]-o或--output 设置输出路径</code></pre><p><strong>清除缓存文件</strong></p><pre><code class="bash">hexo clean</code></pre><p><strong>列出网站资料</strong></p><pre><code class="bash">hexo list &lt;type&gt;</code></pre><p><strong>显示草稿</strong></p><pre><code class="bash">hexo --deaft</code></pre><p><strong>自定义当前工作目录</strong></p><pre><code class="bash">hexo --cwd /path/to/cwd</code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> Hexo </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>第1章 统计学习及监督学习概论</title>
      <link href="/2022/04/10/%E3%80%8A%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E3%80%8B%EF%BC%88%E7%AC%AC%E4%BA%8C%E7%89%88%EF%BC%89/%E7%AC%AC1%E7%AB%A0%20%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E5%8F%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E6%A6%82%E8%AE%BA/"/>
      <url>/2022/04/10/%E3%80%8A%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E3%80%8B%EF%BC%88%E7%AC%AC%E4%BA%8C%E7%89%88%EF%BC%89/%E7%AC%AC1%E7%AB%A0%20%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E5%8F%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E6%A6%82%E8%AE%BA/</url>
      
        <content type="html"><![CDATA[<h3 id="1-统计学习基本分类"><a href="#1-统计学习基本分类" class="headerlink" title="1. 统计学习基本分类"></a>1. 统计学习基本分类</h3><p><strong>监督学习</strong>    <code>学习输入到输出的映射的统计规律</code></p><blockquote><p>1-输入空间、特征空间和输出空间：特征连续预测是回归，离散预测是分类<br>2-联合概率分布：假设输入与输出服从联合分布（关于数据的基本假设）<br>3-假设空间：模型属于由输入空间到输出空间的映射的集合，意味着学习范围的确定。模型可以是概率模型（$P(Y|X)$）或非概率模型$Y&#x3D;f(X)$</p></blockquote><span id="more"></span><p><strong>无监督学习</strong>    <code>学习数据中的统计规律或潜在结构</code></p><blockquote><p>旨在从假设空间中选出在给定评价标准下的最优模型<br>模型可以实现对数据的聚类、降维或概率估计</p></blockquote><p><strong>强化学习</strong>    <code>学习最优的序贯决策</code></p><blockquote><p>强化学习的马尔可夫决策过程是状态、奖励、动作序列上的随机过程，$&lt;S,A,P,r,\gamma&gt;$<br><strong>S</strong>tate、<strong>A</strong>ction、transition <strong>P</strong>robability ($P(s^\prime|s,a)&#x3D;P(s_{t+1}&#x3D;s^\prime|s_t&#x3D;s,a_t&#x3D;a)$)、<strong>r</strong>eward function ($r(s,a)&#x3D;E(r_{t+1}|s_t&#x3D;s,a_t&#x3D;a)$)、discount factor ($\gamma\in[0,1]$)<br>策略$\pi$定义为给定状态下动作的函数$a&#x3D;f(s)$或$P(a|s)$<br>状态价值函数定义为策略$\pi$从某一个状态$s$开始的长期累积奖励的数学期望<br>动作价值函数定义为策略$\pi$从某一个状态$s$和动作$a$开始的长期累积奖励的数学期望</p><p>强化学习方法有基于策略的(policy-based)、基于价值的(value-based)无模型(model-free)方法和有模型(model-based)方法。<br>model-based直接学习马尔科夫决策过程<br>policy-based model-free求解最优策略$\pi^*$<br>value-based model-free求解最优价值函数$q^*(s,a)$</p></blockquote><p><strong>半监督学习</strong>    <code>利用未标注数据中的信息辅助标注数据进行监督学习</code></p><p><strong>主动学习</strong>     <code>找出对学习最有帮助的实例让teacher标注</code></p><h3 id="2-按模型分类"><a href="#2-按模型分类" class="headerlink" title="2. 按模型分类"></a>2. 按模型分类</h3><p><strong>概率模型与非概率模型</strong></p><blockquote><p><strong>基本概率公式</strong><br>加法规则：$P(x)&#x3D;\sum_yP(x,y)$<br>乘法规则：$P(x,y)&#x3D;P(x)P(y|x)$</p></blockquote><p><strong>线性模型与非线性模型</strong></p><p><strong>参数化模型与非参数化模型</strong></p><p>参数化模型假设模型参数的维度固定，模型可以由有限维参数完全刻画；非参数化模型假设模型参数的维度不固定或者说无穷大，随着训练数据量的增加而不断增大。</p><h3 id="3-按算法分类"><a href="#3-按算法分类" class="headerlink" title="3. 按算法分类"></a>3. 按算法分类</h3><p><strong>在线学习与批量学习</strong></p><p>在线学习每次接受一个样本，进行预测，之后学习模型，不断重复；批量学习一次接受所有数据，学习模型，之后进行预测。<br>在线学习可以是监督学习，也可以是无监督学习，强化学习本身就拥有在线学习的特点。</p><h3 id="4-按技巧分类"><a href="#4-按技巧分类" class="headerlink" title="4. 按技巧分类"></a>4. 按技巧分类</h3><p><strong>贝叶斯学习</strong></p><p>在概率模型学习和推理中，利用贝叶斯定理计算在给定数据条件下模型的条件概率，即后验概率，并应用这个原理进行模型的估计，以及对数据的预测。</p><p>贝叶斯估计和极大似然估计代表着统计学中贝叶斯学派和频率学派对统计的不同认识。<br>假设先验分布是均匀分布，取后验概率最大，就能从<code>贝叶斯估计</code>得到<code>极大似然估计</code>。<br>$$<br>D\rightarrow{极大似然估计}\rightarrow\hat{\theta&#x3D;\arg\max_{\theta}P(D|\theta)}\ [图像是只在\hat{\theta}有值]\<br>D\rightarrow{贝叶斯估计}\rightarrow\hat{P}(\theta|D)&#x3D;\frac{P(\theta)P(D|\theta)}{P(D)}\ [图像是正态分布曲线]<br>$$<br><strong>核方法</strong></p><p>核方法是使用核函数表示和学习费线性模型的一种机器学习方法。有一些线性模型的学习方法基于相似度计算&lt;向量內积&gt;，核方法可以把他们扩展到非线性模型的学习中，使其应用更广泛。<br>线性转非线性直接做是显式的定义输入空间到特征空间的映射，在特征空间做內积；核方法不显式的定义这个映射，而是定义核函数&lt;映射之后在特征空间的內积&gt;。<br>$$<br>\frac{输入空间}{x_1,x_2}\stackrel{映射函数\psi}{\longrightarrow}\frac{特征空间}{\psi(x_1),\psi(x_2)}\<br>核函数定义在输入空间\frac{输入空间}{K(x_1,x_2)} \ K(x_1,x_2)&#x3D;&lt;\psi(x_1),\psi(x_2)&gt;<br>$$</p><h3 id="5-统计学习方法三要素"><a href="#5-统计学习方法三要素" class="headerlink" title="5. 统计学习方法三要素"></a>5. 统计学习方法三要素</h3><p><strong>模型</strong></p><p>在监督学习过程中，模型就是所要学习的条件概率分布或决策函数，模型的假设空间（hypothesis space）包含所有可能的条件概率分布或决策函数。</p><p><strong>策略</strong></p><p>损失函数度量模型一次预测的好坏，风险函数度量平均意义下模型预测的好坏。<br>损失函数是$f(X)$和$Y$的<strong>非负</strong>实值函数，记作$L(Y,f(X))$；损失函数的期望是模型$f(X)$关于联合分布$P(x,Y)$的平均意义下的损失，称为风险函数或期望损失$R_{exp}(f)$。<br>$$<br>R_{exp}(f)&#x3D;E_P[L(Y,f(X))]&#x3D;\int_{\mathcal{X}\times\mathcal{Y}}{L(y,f(x))P(x,y)dxdy}<br>$$<br>由于联合分布未知，监督学习就是为了学习联合分布，所以监督学习是一个ill-formed problem。根据大数定律，当样本容量$N$趋于无穷时，经验风险$R_{emp}$趋近于期望风险$R_{exp}$<br>$$<br>R_{emp}(f)&#x3D;\frac{1}{N}\sum_{i&#x3D;1}^N{L(y_i,f(x_i))}<br>$$<br><code>大数定律：说如果统计数据足够大,那么事物出现的频率就能无限接近它的期望值。</code></p><p>由于现实中训练样本数目有限，甚至很小，所以需要矫正。</p><blockquote><p><strong>经验风险最小化</strong><br>$\min_{f\in{F}}\frac{1}{N}\sum_{i&#x3D;1}^N{L(y_i,f(x_i))}$<br>当模型是条件概率分布、损失函数是对数损失函数时，经验风险最小化等价于<code>极大似然估计</code><br><strong>结构风险最小化</strong><br>$R_{srm}(f)&#x3D;\frac{1}{N}\sum_{i&#x3D;1}^N{L(y_i,f(xi))+\lambda J(f)},\ \lambda\ge0$<br>$J(f)$为模型的复杂度，是定义在假设空间的泛函；$\lambda$用以权衡经验风险和模型复杂度<br>当模型是条件概率分布、损失函数是对数损失函数时，模型复杂度由模型的先验概率表示时，结构风险最小化等价于<code>最大后验概率估计</code></p></blockquote><p><strong>算法</strong></p><h3 id="6-模型评估与模型选择"><a href="#6-模型评估与模型选择" class="headerlink" title="6.模型评估与模型选择"></a>6.模型评估与模型选择</h3><p>通常将学习方法对未知数据的预测能力称为泛化能力</p><p><strong>模型选择方法：</strong>正则化和交叉验证</p><p>正则化符合奥卡姆剃刀（Occam’s razor）原理<br><code>如无必要，勿增实体，即简单有效原理</code></p><p>交叉验证：简单交叉（分成两部分）、S折交叉（分成S分）、留一交叉（S&#x3D;N）</p><h3 id="7-泛化误差上界"><a href="#7-泛化误差上界" class="headerlink" title="7.泛化误差上界"></a>7.泛化误差上界</h3><p>$$<br>对二分类问题，泛化误差R(f)：R(f)\le\hat{R}(f)+\epsilon(d,N,\delta),\ \epsilon(d,N,\delta)&#x3D;\sqrt{\frac{1}{2N}(\log{d}+\log\frac{1}{\delta})}\<br>Hoeffding不等式：\forall{t\gt0},P(|\overline{X}-E[\overline{X}]|\ge t)\le2exp(-\frac{2n^2t^2}{\sum_{i&#x3D;1}^{n}(b_i-a_i)^2})<br>$$</p><h3 id="8-监督学习应用"><a href="#8-监督学习应用" class="headerlink" title="8.监督学习应用"></a>8.监督学习应用</h3><p>TP（正确（T）预测为正样例（P））——正预测为正<br>FN（错误（F）预测为负样本（N））——正预测为负<br>FP（错误（F）预测为正样例（P））——负预测为正<br>TN（正确（T）预测为负样本（N））——负预测为负<br>准确率：预测为正的里面真实为正的<br>召回率：真实为正的里面预测为正的</p>]]></content>
      
      
      <categories>
          
          <category> 《统计学习方法》（第二版） </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 学习笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2022/04/10/hello-world/"/>
      <url>/2022/04/10/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><p><strong>To Do</strong></p><blockquote><p>天生带来允许，文化造成封闭 —— 《人类简史》</p></blockquote>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
